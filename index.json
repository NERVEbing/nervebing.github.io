[{"content":"前言 声明 本文是个人对HomeLab即家庭私有实验室的学习探索，参杂着一些经验总结，记录下来，也希望可以让他人少走一些弯路。\nHomeLab是什么？ 本质上是一个连接各种设备的复杂系统，你可以用任何树莓派/PC/服务器/路由器组成一个HomeLab。\nHomeLab能做什么？  搭建属于私人的网盘，不必在各个设备上安装云盘app才能上传/下载文件 不受版权控制的家庭多媒体，集成影视订阅，实现观影追剧自由 集成HomeBridge以实现在iOS/macOS的Home.app中操作非HomeKit认证的设备 BT下载器，无需开启个人电脑，后台下载资源 RSS订阅器，抛弃无意义地刷手机，只获取自己想要的内容 bilibili每日任务/JD京豆获取，各种脚本反薅资本家的羊毛 最重要的是你可以搭建包括但不限于K8S/ELK/MySQL/Redis/Prometheus等各种服务，也可以在上面跑CI/CD自动化构建发布你的代码  阅读门槛  基本的网络知识，比如光猫和路由器的区别，交换机是干什么的 基本的Linux操作，可以理解计算机不是一定要连接显示器才可以操作 遇到问题先使用英文进行Google，内容过长可以开启页面翻译，请不要看CSDN的内容 不求甚解，当你发现你让它跑起来了的时候，会获得极大的心理满足感  设备 架构说明 主要分为服务器和网络设备。考虑到网络设备的稳定性及网络隔离对整套系统的重要程度，没有采用虚拟化AIO(ALL IN ONE)方案。\n作为服务端开发者看来所谓的AIO毫无稳定性可言，ESXi的OpenWrt虚拟机出了故障会影响其他业务虚拟机的运行，甚至连iLO后台都进不去，需要连接显示器手动配置ESXi进行修复，这种情况在异地操作HomeLab节点的时候是毁灭性的灾难。\n当然这种方式的好处也有：网上教程多，按视频操作一步步做几乎没有难点，小白也能轻松搭建。\n缺点就是对整体的HomeLab环境一知半解甚至根本不懂，只会复制粘贴。当然你可以说“我只是想快速搭建一整套服务，不想了解细节”，这样的话本文可能不适合你。\n服务器 首先是最重要的服务器部分，绝大多数设备购入时间为2021年2-3月，价格相比当前可能有很大差距，费用清单如下：\n   设备 价格(元) 数量 备注     HPE Gen10 Plus G5420/8GB 4000 1 淘宝/德国转运   iLO5 NIC Kit 399 1 同上   Intel 志强 E-2146G 1400 1 淘宝/QS版   海力士 32GB DDR4 2666MHz ECC 2600 2 淘宝   希捷 Exos X18 16TB 4200 2 淘宝/国行   英睿达 MX500 SATA SSD 2TB 2400 2 京东自营   三星 PM991 256GB + 佳翼硬盘盒 300 1 PM991闲鱼/硬盘盒京东   三星 850PRO SATA SSD 256G 0 2 家用闲置   Intel 傲腾 NVMe SSD 16GB 0 2 家用闲置   Intel 奔腾 G5420 -488 1 闲鱼出了   HPE 原装海力士 8GB ECC -300 1 闲鱼出了   盈通 GTX1650 4GB DDR6 85 1 1535购入/1450出了   佳翼 NVMe 4X4 阵列卡 1200 1 淘宝   总计 15796      之前没怎么认真统计花费，看到总计后还是惊了一下，老实说这个价格可以上塔式服务器或者洋垃圾DIY。选择Gen10 Plus的理由无外乎精致/美观/静音，毕竟这是一台可以放在卧室的服务器。\n总的来说硬盘/存储占比重较大，当前情况下的配置不是最终配置，目的也仅仅是为了满足个人需求。\n如果能把硬盘换成SATA SSD 4TB * 4会更好，当然NVMe阵列卡插满4条m.2也可，主做NAS服务器的话直接更换为10G/25G/40G网卡。配置是为了匹配实际用途，否则就是卑鄙的浪费。\n主机 主机从下单到收货前前后后差不多一个月的时间。  开箱，高贵的日耳曼甜美空气扑面而来(doge)。\n  即使在公司加班也阻止不了我欣赏它的美。\n  拧开快拆螺丝，欣赏大厂的工整做工，简直是一件艺术品。\n CPU 首先我们要知道Gen10 Plus的DC电源是180W，在官方高配也就是Intel志强E-2224/16GB/单SSD的情况下整机功耗能达到110W，最多只能留下70W的可用空间。考虑到电源转换效率以及需要留点余量(20W)，这样我们可以操作的空间就只剩下50W。\n每一块希捷 Exos X18 16TB的待机功耗大概是5W，满载功耗是10W，4块满载40W，这么看来光是硬盘塞满的情况下电源就已经快撑不住了，更别提上个网卡或显卡了。\n然而事实是我们不会让服务器始终跑在100%的负载下，也就是说功耗峰值不代表日常功耗。根据我目前的配置，待机功耗在35W左右，目前跑了20+个服务的情况下也不过50W，程序的CPU占用率也可以在docker命令中加以限制。\n现在我们再来看CPU的选择：\n 上图来自servethehome.com的HPE ProLiant MicroServer Gen10 Plus Ultimate Customization Guide一文，是一篇非常好的HPE Gen10 Plus设备选择指导。\n 根据servethehome.com的测试结果，当使用E-2288G/64GB/单SSD在Windows Server 2019上跑Prime95时，功率计上的数值达到了194.5W，所以8核16线程直接排除。\n由于跑大量服务需要更多的核心/线程数，并且官方高配就是4核4线程，所以我们筛选6核12线程的CPU如下：\n   型号 核心/线程数 频率 TDP(W)     基准 E-2224 4C/4T 3.4-4.6GHz 71W   E-2276G 6C/12T 3.8-4.9GHz 80W   E-2246G 6C/12T 3.6-4.8GHz 80W   E-2236 6C/12T 3.4-4.8GHz 80W   E-2176G 6C/12T 3.7-4.7GHz 80W   E-2146G 6C/12T 3.5-4.5GHz 80W   E-2136 6C/12T 3.3-4.5GHz 80W    最好的选择当然是E-2276G，但当时E-22XX系列太贵了，而且志强8代与9代性能差距不大，所以范围缩小成了E-2176G、E-2146G、E-2136三款。\n根据CPU Benchmarks的对比结果来看三款在跑分上基本上可以说是没什么差距，由于E-2146G相比E-2136多了核显，虽然Gen10 Plus主板屏蔽了核显，但以后可以等E-2278G价格亲民后进行置换，拆下来E-2146G可以给别的机器用，所以最终选择了E-2146G。\n 淘宝1400拿下E-2146G QS正显，步进和正式版相同e4，成色相当之好，插上点亮。\n  iLO中处理器信息一切正常。\n  稍微测了下，睿频4.5GHz，全核心满载4.2GHz，此时CPU温度85度左右，插座显示120W，对这个结果相当满意。\n 内存 HPE Gen10 Plus官方产品页上写的最大支持内存是32GB，实测支持64GB，且不像Gen8，Gen10 Plus支持非ECC内存，给预算不充足的玩家留足了余地。\nHPE的原装内存是海力士的8GB DDR4 ECC 2666MHz，在奔腾G5420下只能以2400MHz运行，不多说直接挂闲鱼。\n32GB纯ECC内存的选择有三星和海力士。三星由于贴牌寨条较多，正品库存少不好买，海力士也是HPE认证内存厂商，所以选择了后者。\n iLO内存信息，64GB DDR4 2666MHz ECC，双通道运行。\n  奇怪的是制造商一栏显示不适用，但其他信息完全正常，Reddit上查到只有官方部件号的16GB单条才有制造商信息，无所谓了。\n 硬盘 HDD HDD选择了两块加拿大白嫖王多次认证的希捷Exos X18 16TB，没什么好说的。购入的时候单价2100(2021.3)，一个月后Chia大火价格翻了一倍，目前价格降到了1800(2022.5)左右，早知道当时应该出了。\n 出色的稳定性和相对较低的磁盘共振噪音让Exos X18依旧相较于WD Ultrastar DC HC550来说是更好的选择。\n 1smartctl -a /dev/sda |grep Temperature_Celsius 2Temperature_Celsius 33 3smartctl -a /dev/sdb |grep Temperature_Celsius 4Temperature_Celsius 34  日常待机温度也让人相当安心。\n  悲催的是其中一块在插到另一台机器上调试的时候，SATA接口附近的塑料片被带掉了下来。联系了售后，要上海解封后才能换接口，先用一块三星 850 PRO 256G做系统盘。\n SSD 既然要跑服务，HDD的读写速度当然是不够看的。Intel D3-S4610、Intel D3-S4510等企业级SSD除了贵没有任何缺点，但闲鱼上全是高强度锻炼清零盘，实在让人买不下手。\n于是目光转向便宜大碗的京东自营英睿达 MX500 2TB。\n 刚好有活动单价1199拿下，5年质保。英睿达京东自营算是全球指定售后点，出了问题基本上直接换新。\n PCIe PCIe插槽的选择是最让人纠结的地方，由于Gen10 Plus内部只有一个PCIe 3.0 X16 单槽/半高插槽，能使用的配件主要有下面几个类型：\n 显卡 网卡 SAS卡 PCIe SSD/PCIe转NVMe转接卡  显卡 选择显卡的理由显而易见：可以硬解Jellyfin/Emby；可以跑CUDA；可以虚拟化环境中直通到Windows打游戏。\n功耗是不得不考虑的问题，PCIe X16可提供功耗为70W，高负载模式下对Gen10 Plus的供电来说是不小的挑战。\n本人为了硬解视频先后尝试了Radeon RX550/GeForce GTX 1650，总的来说ESXi环境中A卡的兼容性会好一些，但在特定的应用中转换效率较低；N卡(指1650这样的非专业卡)在ESXi7.0中的表现极差，费劲直通到Windows却做不到持久化，虚拟机重启就会失效，说到底还是ESXi对消费级显卡的不兼容，但在纯docker环境中N卡的视频解码表现远比A卡要强。\n 上图为盈通GeForce GTX1650 4GB DDR6，目前(2022.1)不用外接电源单槽半高最强显卡，HTPC最优选择，支持各种视频解码。145mm全长/纯铜散热片，做工扎实，丽台同款价格2699，除了logo其他完全一样。\n 网卡 由于2.5G/5G都可以通过USB3.0的方式转换，这里推荐威联通（QNAP）5G转换器，在Linux下也有很好的兼容性。\n10G(万兆)分为电口(RJ45)和光口(SFP+)，Gen10 Plus的PCIe区域是没有风道的，从功耗和散热来说，光口更值得推荐。如果有主做NAS需求的话，推荐Intel X710-DA4，但记得同时购入光转电模块。\n25G及以上不在本文讨论范围内。\nSAS卡 除非有非常强烈的硬RAID需求，否则不推荐SAS卡占用唯一的PCIe插槽这样的宝贵资源。\nPCIe SSD/PCIe转NVMe转接卡 PCIe SSD可以选择Intel DC P3608或Intel 傲腾 SSD 905P，但这类企业级PCIe太贵了，比较常用的做法是PCIe转NVMe转接卡类似佳翼冷雨燕NVMe转接卡这类经济实惠的方案。\n需要注意的是，如果想要PCIe转接多条m.2 NVMe的话，需要购买自带主控芯片的拆分卡，我的选择是佳翼 NVMe阵列卡 4x4 SSD PCIE转M.2转接卡。\n 自带ASM2824主控支持拆分，不挑主板，带涡轮风扇。热量主要来自于SSD的芯片和主控，加上PCIe区域通风不佳，散热只能说马马虎虎，不是这张卡的问题。\n 1smartctl -a /dev/nvme0n1 |grep Temperature 2Temperature: 52 Celsius 3smartctl -a /dev/nvme1n1 |grep Temperature 4Temperature: 53 Celsius  风扇转速14%的情况下，最热的07-BMC其实是iLO芯片，下面的10-PCI 1 Zone在低负载下其实温度还行。\n 网络设备 OpenWrt 比较推荐J4125 四口2.5G软路由，比如康耐信J4125 I225-V 2.5G这款，看评测比倍控的方案散热好一些，日后换2.5G口的AP也比较合适。\n有树莓派的话也可以用树莓派，做个类似这样的方案：\n 树莓派4B + 5口千兆交换机 + USB千兆网卡，小巧又精致。\n 由于老家是老房子，装修的时候还是百兆网线，手头一个斐讯N1就够用了。\n固件选择kiddin9或者gd0772。\nWi-Fi Mesh 目前是红米AX6S + 小米AX1800组Mesh，对Wi-Fi速率需求没那么高，信号覆盖范围广就可以。\n其他 UPS不间断电源 UPS选择的是APC BK650M2-CH，390W带服务器+路由器+交换机足够用了。\n1# apt安装守护进程 2sudo apt install -y apcupsd 3 4# 修改配置文件后保存 5sudo vim /etc/apcupsd/apcupsd.conf 6 7UPSNAME APC-BK650M2 # 随意修改 8UPSCABLE usb 9UPSTYPE usb 10DEVICE # 留空 11 12# 重启服务 13systemctl restart apcupsd.service 14 15# 查看运行情况 16apcaccess 17 18APC : 001,036,0873 19DATE : 2022-05-12 15:09:50 +0800 20HOSTNAME : lvlv-Gen10Plus 21VERSION : 3.14.14 (31 May 2016) debian 22UPSNAME : APC-BK650M2 23CABLE : USB Cable 24DRIVER : USB UPS Driver 25UPSMODE : Stand Alone 26STARTTIME: 2022-05-07 09:48:38 +0800 27MODEL : Back-UPS BK650M2-CH 28STATUS : ONLINE 29LINEV : 235.0 Volts 30LOADPCT : 13.0 Percent 31BCHARGE : 100.0 Percent 32TIMELEFT : 29.9 Minutes 33MBATTCHG : 5 Percent 34MINTIMEL : 3 Minutes 35MAXTIME : 0 Seconds 36SENSE : Low 37LOTRANS : 160.0 Volts 38HITRANS : 278.0 Volts 39ALARMDEL : 30 Seconds 40BATTV : 13.5 Volts 41LASTXFER : No transfers since turnon 42NUMXFERS : 0 43TONBATT : 0 Seconds 44CUMONBATT: 0 Seconds 45XOFFBATT : N/A 46SELFTEST : NG 47STATFLAG : 0x05000008 48SERIALNO : 9B2131A03464 49BATTDATE : 2001-01-01 50NOMINV : 220 Volts 51NOMBATTV : 12.0 Volts 52NOMPOWER : 390 Watts 53FIRMWARE : 294803G -292804G 54END APC : 2022-05-12 15:10:03 +0800 ","permalink":"https://blog.lvlv.fun/posts/2022-05-08/","summary":"前言 声明 本文是个人对HomeLab即家庭私有实验室的学习探索，参杂着一些经验总结，记录下来，也希望可以让他人少走一些弯路。\nHomeLab是什么？ 本质上是一个连接各种设备的复杂系统，你可以用任何树莓派/PC/服务器/路由器组成一个HomeLab。\nHomeLab能做什么？  搭建属于私人的网盘，不必在各个设备上安装云盘app才能上传/下载文件 不受版权控制的家庭多媒体，集成影视订阅，实现观影追剧自由 集成HomeBridge以实现在iOS/macOS的Home.app中操作非HomeKit认证的设备 BT下载器，无需开启个人电脑，后台下载资源 RSS订阅器，抛弃无意义地刷手机，只获取自己想要的内容 bilibili每日任务/JD京豆获取，各种脚本反薅资本家的羊毛 最重要的是你可以搭建包括但不限于K8S/ELK/MySQL/Redis/Prometheus等各种服务，也可以在上面跑CI/CD自动化构建发布你的代码  阅读门槛  基本的网络知识，比如光猫和路由器的区别，交换机是干什么的 基本的Linux操作，可以理解计算机不是一定要连接显示器才可以操作 遇到问题先使用英文进行Google，内容过长可以开启页面翻译，请不要看CSDN的内容 不求甚解，当你发现你让它跑起来了的时候，会获得极大的心理满足感  设备 架构说明 主要分为服务器和网络设备。考虑到网络设备的稳定性及网络隔离对整套系统的重要程度，没有采用虚拟化AIO(ALL IN ONE)方案。\n作为服务端开发者看来所谓的AIO毫无稳定性可言，ESXi的OpenWrt虚拟机出了故障会影响其他业务虚拟机的运行，甚至连iLO后台都进不去，需要连接显示器手动配置ESXi进行修复，这种情况在异地操作HomeLab节点的时候是毁灭性的灾难。\n当然这种方式的好处也有：网上教程多，按视频操作一步步做几乎没有难点，小白也能轻松搭建。\n缺点就是对整体的HomeLab环境一知半解甚至根本不懂，只会复制粘贴。当然你可以说“我只是想快速搭建一整套服务，不想了解细节”，这样的话本文可能不适合你。\n服务器 首先是最重要的服务器部分，绝大多数设备购入时间为2021年2-3月，价格相比当前可能有很大差距，费用清单如下：\n   设备 价格(元) 数量 备注     HPE Gen10 Plus G5420/8GB 4000 1 淘宝/德国转运   iLO5 NIC Kit 399 1 同上   Intel 志强 E-2146G 1400 1 淘宝/QS版   海力士 32GB DDR4 2666MHz ECC 2600 2 淘宝   希捷 Exos X18 16TB 4200 2 淘宝/国行   英睿达 MX500 SATA SSD 2TB 2400 2 京东自营   三星 PM991 256GB + 佳翼硬盘盒 300 1 PM991闲鱼/硬盘盒京东   三星 850PRO SATA SSD 256G 0 2 家用闲置   Intel 傲腾 NVMe SSD 16GB 0 2 家用闲置   Intel 奔腾 G5420 -488 1 闲鱼出了   HPE 原装海力士 8GB ECC -300 1 闲鱼出了   盈通 GTX1650 4GB DDR6 85 1 1535购入/1450出了   佳翼 NVMe 4X4 阵列卡 1200 1 淘宝   总计 15796      之前没怎么认真统计花费，看到总计后还是惊了一下，老实说这个价格可以上塔式服务器或者洋垃圾DIY。选择Gen10 Plus的理由无外乎精致/美观/静音，毕竟这是一台可以放在卧室的服务器。","title":"基于HPE MicroServer Gen10 Plus的HomeLab搭建 - 硬件篇"},{"content":"MySQL存储结构  B-tree 是平衡的多路查找树。 涉及到磁盘的查找需要设法减少磁盘 I/O 次数。 B-tree 就是为解决这个问题而引入的数据结构。   区别于二叉树 b-tree 可以拥有很多个子节点（这个度量被称为「内结点出度」) 我们可以在技术上使 B-tree 的结点大小为磁盘一个页的大小，并且在新建结点时直接申请一个页大小的空间，使得结点的物理存储位置也是在一个页里，这样就能实现存取一个结点只需一次磁盘 I/O 在最坏情况下，B-tree 的一次检索最多需要H（树的高度）次的磁盘 I/O 实际上，为了取得更大的内结点出度，各个数据库一般会采用 B-tree的变种如 B+-tree，B*-tree 来实现索引，比如 MySQL 的存储引擎 InnoDB 就采用 B+-tree 来实现聚簇索引  索引  字符串索引，长度限制 innodb 存储引擎，默认前缀长度最大能支持767字节；而在开启innodb_large_prefix属性值的情况下，最大能支持3072字节 前缀索引，后缀索引，手动md5哈希索引 innode内置哈希 Cardinality 不重复值预估 ，除以记录总数的比例 尽量接近1 索引的价值越大 查询优化器 选择索引时会考虑这个值 oltp olap Online Analytical Processing Online transaction processing  索引细节  单列索引币复合索引在每个数据页存的记录要多，所以查询优化器优先使用单列索引 覆盖索引 数据最小读取单位(索引页？) count(*) 操作，实际会读取辅助索引，避免读取聚合索引 统计操作，覆盖索引的情况下，可以直接查询复合索引(a,b) 中的b index hint 索引提示 use index 只是提示，force index才是强制 multi-range read 优化 从辅助索引筛选完之后，将结果，已主键进行排序，再去读聚合索引下的记录行 index condition pushdown （IPC）优化，将where 过滤条件推送到存储引擎，减少数据传输 (使用时会提示 using index condition) innodb 全文索引 使用倒排索引实现 ，使用了FTS Index Cache 缓存数据变更，批量更新到Auxiliary Table中(这个表可以通过关键词定位到文档，单词位置)  锁   myisam 只支持表锁，sql server 2005版之前只支持页锁，2005开始支持行锁，但是实现方式与innodb不同，加锁会有资源开销，innodb则与oracle 的锁实现类似\n  lock 锁，与latch锁， lock用于事务，latch用于保证并发下的数据一致性（临界资源）\n  查看latch锁 show engine innodb mutex;\n  查看lock 锁 show engine innodb status;\n  共享锁 s Lock，允许事务读一行数据，共享锁可以叠加，称为锁兼容\n  排他锁 x Lock,允许事务删除或者更新一行数据\n  意向锁 (Intention Lock) ,对子级上锁，需要怼父级上意向锁，s锁，对应is,x锁对应ix\n  查看锁的情况，show full processlist,show engine innodb status, information_schema下的，innodb_trx,innodb_locks,innodb_lock_waits 等三张表\n  如果没有合适的索引，则innodb会使用主键来进行锁定(可能会造成表锁)\n  索引含有唯一属性时，where id=1 类似的查询Next-Key Lock 会降级为Record Lock\n  锁的问题   脏读 (read uncommited级别下)脏数据是事务对缓冲池中的行记录的修改，并且没有被提交(commit),脏读就是读到了未提交数据\n  不可重复读 (read commited级别下) 在当前事务两次读取不一致，第二次读到了其他事务提交的数据\n  丢失更新 一个事务的更新，被另外一个事务覆盖，数据库本身不会发生这个错误，程序缓存变量值再写入时可能发生\n  阻塞 innodb 默认不会回滚阻塞超时引发的异常\n  死锁 基础是等待一方超时，innodb还采用 wait-for graph(等待图) 深度优先算法 采用递归实现(innodb 1.2之后采用非递归方式实现递归)\n  发生死锁的因素 1.并发事务数量 2.每个事务操作的数量 3.操作数据的集合大小，集合越大越不容易冲突\n  innodb一般情况出错，不会回滚事务，但是死锁除外，死锁时，innodb会回滚其中一个事务，死锁报错(1213)\n  事务   ACID 原子性(atomicity) 一致性(consistency) 隔离性(isolation) 持久性(durability)\n  事务的分类 扁平事务(Flat Transactions) 带有保存点的扁平事务(Flat Transactions with Savepoints) 链事务(Chained Transactions) 嵌套事务(Nested Transactions) 分布式事务(Distributed Transactions)\n  事务的隔离性由锁来实现\n  事务的原子性，一致性，持久性 通过 redo log和undo log来完成\n  Innodb不支持嵌套事务，当执行一个START TRANSACTION指令时，会隐式的执行一个commit操作。\n  事务控制   innodb默认是自动提交的(auto commit)\n  begin/start transaction 显示的开启事务\n  隐式提交的sql语句:alter 等修改表结构，修改数据库的语句\n  事务操作的统计 com_commit与com_rollback (默认是自动提交autocommit=1,不会记入这两字段) show global status like ‘com_commit’\n  另外两个参数 handler_commit与handle_rollback\n  事务隔离级别\n     隔离级别Isolation Level 脏读Dirty Read 不可重复读NonRepeatable Read 幻读Phantom Read     未提交读Read uncommitted 可能 可能 可能   已提交读Read committed 不可能 可能 可能   可重复读Repeatable read 不可能 不可能 可能   可串行化Serializable 不可能 不可能 不可能     未提交读(Read Uncommitted)：\n允许脏读，也就是可能读取到其他会话中未提交事务修改的数据。\n  已提交读(Read Committed)：\n只能读取到已经提交的数据。Oracle等多数数据库默认都是该级别（不重复读）。\n  可重复读(Repeated Read)：\n可重复读。在同一个事务内的查询都是事务开始时刻一致的，InnoDB默认级别。在SQL标准中，该隔离级别消除了不可重复读，但是还存在幻象读。\n  可串行化(Serializable)：\n完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞，innodb在repeatable read隔离级别下就能达到3度的隔离，所以一般不需要serializable。\n  幻读，并不是说两次读取获取的结果集不同，幻读侧重的方面是某一次的 select 操作得到的结果所表征的数据状态无法支撑后续的业务操作。更为具体一些：select 某记录是否存在，不存在，准备插入此记录，但执行 insert 时发现此记录已存在，无法插入，此时就发生了幻读。\n 分布式事务   innodb 支持XA事务，通过XA事务来支持分布式事务的实现\n  XA事务支持不同数据库之间的分布式事务\n  XA事务由一个或多个资源管理器(Resource Managers),一个事务管理器(Transaction Manager)以及一个应用程序(Application Program)组成\n  资源管理器:提供访问事务资源的方法，通常就是数据库\n  事务管理器:协调参与全局事务中的各个事务 (MySQL服务器的客户端)\n  应用程序:定义事务的边界，指定全局事务中的操作\n  Java的JTA(Java Transaction API)可以很好的支持MySQL的分布式事务\n  MySQL内部也存在另外一种内部XA事务，在存储引擎与插件直接，或者不同存储引擎之间\n  最常见的内部XA事务是binlog与innodb存储引擎之间\n  不好的事务习惯，在循环中提交事务 使用自动提交，使用自动回滚\n  日志   redo log 重做日志 用来保证事务的原子性和持久性， redo log 有单独的文件保存\n  redo log 记录物理修改，某个表空间，某个页，某条记录的值\n  redo log 分为两部分 内存中的 redo log buffer 重做日志文件 redo log file\n  事务提交时，必须将重做日志持久化，才算完成，即每次提交commit,写入重做日志到磁盘后都会调用fsync，强制写入到磁盘，避免停留在文件系统的写入缓冲\n  通过修改配置可以改变重做日志刷新模式， innodb_flush_log_at_trx_commit 默认为1，改为0不写入重做日志，而是等待一个时间周期(1s)后由master thread统一操作，设置为2表示提交时仅写入文件系统缓存\n  innodb_flush_log_at_trx_commit 改为0或2时，对事务性能有明显的提升，但是在特定的条件下会牺牲数据的一致性，即写入到缓存而未刷新到硬盘\n  redo log 以512字节进行存储，以块(block)的方式进行保存， 称为重做块日志 redo log block\n  block 大小与磁盘扇区大小一致，保证写入的原子性，不需要doublewrite技术\n  innodb1.2之前，重做日志总大小要小于4G,innodb1.2开始限制提高到512G\n  重做日志，格式 redo_log_type:重做日志类型 space:表空间id page_no:也的偏移量\n  LSN(Log Sequence Number)日志序列号 含义:1.重做日志写入的字节总量 2.checkpoint的位置 3:页的版本\n  show engine innodb status 可以查看lsn的情况\n  Log sequence number 当前的LSN Log flushed up to 表示刷新到重做日志文件的LSN Pages flushed up to Last checkpoint at 刷新到磁盘的LSN\n  生成环境这几个的值可能不同\n  undo log 用来保证事务的一致性，undo log 默认存放在共享表空间中的undo 段中(undo segment)，innodb1.2开始可以修改配置，存放在单独的文件中\n  undo log 记录逻辑修改，回滚时反向操作\n  mvcc就是通过undo log来实现\n  innodb1.1之前 只有一个rollback segment,每个回滚段记录了1024个undo log segment,所以innodb1.1之前只支持并发1024个事务\n  innodb1.1开始支持最大128个rollback segment 所以支持同时在线事务的数量为128*1024\n  事务提交后不能马上删除undo log，因为可能还有其他事务需要读取事务提交前的行记录版本，由单独的pure线程来判断是否需要最终删除undolog\n  undo 页可以重用\n  History list length 代表undo log的数量，purge 会减少这个数量\n  innodb还不能直接查看undo信息。 innosql对information_schema进行扩展，添加了两张数据字典表来查看undo信息 innodb_trx_rollback_segment,查看rollbacksetment,innodb_trx_undo 记录undo log\n  relay log relay log很多方面都跟binary log差不多，区别是：从服务器I/O线程将主服务器的二进制日志读取过来记录到从服务器本地文件，然后SQL线程会读取relay-log日志的内容并应用到从服务器。\n  group commit 一次fsync确保多个事务日志被写入文件\n  innodb1.2之前开启二进制日志后，group commit会失效，因为开启二进制日志后，为了保证存储引擎层的事务与二进制日志的一致性，必须每个步骤都使用fsync，使用prepare_commit_mutex保证顺序 ** 1) 当事务提交时，Innodb存储引擎进行prepare操作 ** 2) MySQL数据库上层写入二进制日志 (fsync由sync_binlog控制) ** 3) Innodb粗糙你引擎层将日志写入重做日志问的 a)修改内存中事务对应的信息，并且将日志写入重做日志缓冲 b)调用fsync将确保日志都从重做日志缓冲写入磁盘 (fsync由 innodb_flush_log_at_trx_commit参数控制)\n  MySQL5.6实现了BLGC(Binary Log Group Commit) 使得数据库层与innodb存储引擎层都实现了group cimmit ,移除了 prepare_commit_mutex锁，提高了性能\n  二进制日志(binlog) ,用来进行POINT-IN-TIME(PIT)的恢复，以及主从复制(Replication)环境的建立\n  重做日志由innodb产生，二进制日志则是在MySQL数据库层产生,对任何存储引擎都会产生二进制日志\n  二进制日志是逻辑日志，记录的是对应的sql语句，而重做日志是物理格式日志\n  二进制日志是事务提交后一次写入，而重做日志是事务每次操作都写入\n  重做日志是幂等的，二进制日志不是\n  binlog 分为 statement与row两种类型\n  备份与恢复   备份方式 mysqldump,ibbackup,replication,第三方工具:xtrabackup,LVM快照备份\n  热备(Hot Backup) 数据库运行中直接无影响备份 冷备(Cold Backup) 数据库停机时备份，(复制物理文件) 温备 (Warm Backup) 数据库运行中有影响备份，(e.g加全局读锁)\n  逻辑备份，裸文件备份\n  完全备份， 增量备份，MySQL本身没有增量备份，通过二进制日志来完成增量备份(效率很低)，可以使用xtrabackup工具 日志备份 二进制日志文件\n  性能调优   选择64位CPU,64位MySQL\n  内存，在达到MySQL数据本身大小前，内存与性能，线性增加\n  机械硬盘与固态硬盘，不同特性对性能的影响， 机械硬盘，随机读性能差，固态硬盘随机读性能好，但是覆盖更新性能有局限，根据不同硬件情况来调整参数与程序设计\n  合理的设置RAID， 有的RAID卡支持写入缓存，可以很好的提高性能，同时注意需要内置UPS电源才能避免数据丢失\n  部分文件系统支持文件快照\n  不同操作系统对MySQL有不同的影响\n  选择合适的基准测试工具sysbench ,mysql-tpcc\n  ","permalink":"https://blog.lvlv.fun/posts/2019-10-29/","summary":"MySQL存储结构  B-tree 是平衡的多路查找树。 涉及到磁盘的查找需要设法减少磁盘 I/O 次数。 B-tree 就是为解决这个问题而引入的数据结构。   区别于二叉树 b-tree 可以拥有很多个子节点（这个度量被称为「内结点出度」) 我们可以在技术上使 B-tree 的结点大小为磁盘一个页的大小，并且在新建结点时直接申请一个页大小的空间，使得结点的物理存储位置也是在一个页里，这样就能实现存取一个结点只需一次磁盘 I/O 在最坏情况下，B-tree 的一次检索最多需要H（树的高度）次的磁盘 I/O 实际上，为了取得更大的内结点出度，各个数据库一般会采用 B-tree的变种如 B+-tree，B*-tree 来实现索引，比如 MySQL 的存储引擎 InnoDB 就采用 B+-tree 来实现聚簇索引  索引  字符串索引，长度限制 innodb 存储引擎，默认前缀长度最大能支持767字节；而在开启innodb_large_prefix属性值的情况下，最大能支持3072字节 前缀索引，后缀索引，手动md5哈希索引 innode内置哈希 Cardinality 不重复值预估 ，除以记录总数的比例 尽量接近1 索引的价值越大 查询优化器 选择索引时会考虑这个值 oltp olap Online Analytical Processing Online transaction processing  索引细节  单列索引币复合索引在每个数据页存的记录要多，所以查询优化器优先使用单列索引 覆盖索引 数据最小读取单位(索引页？) count(*) 操作，实际会读取辅助索引，避免读取聚合索引 统计操作，覆盖索引的情况下，可以直接查询复合索引(a,b) 中的b index hint 索引提示 use index 只是提示，force index才是强制 multi-range read 优化 从辅助索引筛选完之后，将结果，已主键进行排序，再去读聚合索引下的记录行 index condition pushdown （IPC）优化，将where 过滤条件推送到存储引擎，减少数据传输 (使用时会提示 using index condition) innodb 全文索引 使用倒排索引实现 ，使用了FTS Index Cache 缓存数据变更，批量更新到Auxiliary Table中(这个表可以通过关键词定位到文档，单词位置)  锁   myisam 只支持表锁，sql server 2005版之前只支持页锁，2005开始支持行锁，但是实现方式与innodb不同，加锁会有资源开销，innodb则与oracle 的锁实现类似","title":"MySQL/innoDB内部实现"},{"content":"前提 因产品需求，需用PHP（v7.0.12）调用k8s集群中gRPC（golang@1.12.0）服务。\n问题 经过dev环境测试，当php-fpm启动后第一次调用或者距离上次调用时间20分钟后左右，再次请求gRPC微服务接口，就会返回 Connection reset by peer 错误，说明gRPC服务端或者客户端主动关闭连接了。继续发起请求到服务端，又恢复正常。\n思考 经查阅相关资料，发现问题可能出现在k8s集群的kube-proxy模式上。当前k8s环境(dev)下的kube-proxy为ipvs模式，服务端与客户端之间通信如下：\n把上图client看成是apsopen-inside服务pod，Backend pod(1~3)看成gRPC服务，可以看出它们之间的交互路径：\n1 ---\u0026gt; gRPC server pod1 2gRPC-client ---\u0026gt; ipvs ---\u0026gt; gRPC server pod3 3 ---\u0026gt; gRPC server pod3 我们知道gRPC是基于HTTP/2协议的，gRPC的client和server在交互时会建立多条连接，为了性能，这些连接都是长连接并且是一直保活的。 这段环境中不管是客户端服务还是gRPC服务都被调度到各个相同配置信息的Kubernetes节点上，这些k8s节点的 keep-alive 是一致的，如果出现连接主动关闭的问题，因为从client到server经历了一层ipvs，所以最大的可能就是ipvs出将连接主动断开，而client端还不知情。 搜索 ipvs timeout 关键字找到了下面相关的链接：\n https://github.com/moby/moby/issues/31208 https://success.docker.com/article/ipvs-connection-timeout-issue https://github.com/kubernetes/kubernetes/issues/32457  其中 https://github.com/moby/moby/issues/31208 中是关于docker swarm在overlay网络下长连接的问题，这个和k8s kube-proxy应该是类似的，按照这个链接中的描述查看 我们这套环境关于tcp keepalive的内核参数：\n1#进入igo-util-shorturi容器 2 3sysctl net.ipv4.tcp_keepalive_time net.ipv4.tcp_keepalive_probes net.ipv4.tcp_keepalive_intvl 4net.ipv4.tcp_keepalive_time = 7200 5net.ipv4.tcp_keepalive_probes = 9 6net.ipv4.tcp_keepalive_intvl = 75 上面这段参数的含义: net.ipv4.tcp_keepalive_time 是连接时长，当超过这个时间后，每个 net.ipv4.tcp_keepalive_intvl 的时间间隔会发送keepalive数据包， net.ipv4.tcp_keepalive_probe 是发送keepalived数据包的频率。\n解决 使用 ipvsadm 命令查看k8s节点上ipvs的超时时间：\n1ipvsadm -l --timeout 2Timeout (tcp tcpfin udp): 900 120 300 可以看出，各个k8s节点上tcp keepalive超时是7200秒(即2小时)，ipvs超时是900秒(15分钟)，这就出现如果客户端或服务端在15分钟内没有应答时，ipvs会主动将tcp连接终止，而客户端还以为超时间依然是2个小时。 很明显 net.ipv4.tcp_keepalive_time 不能超过ipvs的超时时间。\n调节k8s节点上的tcp keepalive参数如下：\n1net.ipv4.tcp_keepalive_time = 600 2net.ipv4.tcp_keepalive_intvl = 30 3net.ipv4.tcp_keepalive_probes = 10 再去测试Connection reset by peer问题已经解决。\n","permalink":"https://blog.lvlv.fun/posts/2019-07-22/","summary":"前提 因产品需求，需用PHP（v7.0.12）调用k8s集群中gRPC（golang@1.12.0）服务。\n问题 经过dev环境测试，当php-fpm启动后第一次调用或者距离上次调用时间20分钟后左右，再次请求gRPC微服务接口，就会返回 Connection reset by peer 错误，说明gRPC服务端或者客户端主动关闭连接了。继续发起请求到服务端，又恢复正常。\n思考 经查阅相关资料，发现问题可能出现在k8s集群的kube-proxy模式上。当前k8s环境(dev)下的kube-proxy为ipvs模式，服务端与客户端之间通信如下：\n把上图client看成是apsopen-inside服务pod，Backend pod(1~3)看成gRPC服务，可以看出它们之间的交互路径：\n1 ---\u0026gt; gRPC server pod1 2gRPC-client ---\u0026gt; ipvs ---\u0026gt; gRPC server pod3 3 ---\u0026gt; gRPC server pod3 我们知道gRPC是基于HTTP/2协议的，gRPC的client和server在交互时会建立多条连接，为了性能，这些连接都是长连接并且是一直保活的。 这段环境中不管是客户端服务还是gRPC服务都被调度到各个相同配置信息的Kubernetes节点上，这些k8s节点的 keep-alive 是一致的，如果出现连接主动关闭的问题，因为从client到server经历了一层ipvs，所以最大的可能就是ipvs出将连接主动断开，而client端还不知情。 搜索 ipvs timeout 关键字找到了下面相关的链接：\n https://github.com/moby/moby/issues/31208 https://success.docker.com/article/ipvs-connection-timeout-issue https://github.com/kubernetes/kubernetes/issues/32457  其中 https://github.com/moby/moby/issues/31208 中是关于docker swarm在overlay网络下长连接的问题，这个和k8s kube-proxy应该是类似的，按照这个链接中的描述查看 我们这套环境关于tcp keepalive的内核参数：\n1#进入igo-util-shorturi容器 2 3sysctl net.ipv4.tcp_keepalive_time net.ipv4.tcp_keepalive_probes net.ipv4.tcp_keepalive_intvl 4net.ipv4.tcp_keepalive_time = 7200 5net.ipv4.tcp_keepalive_probes = 9 6net.ipv4.tcp_keepalive_intvl = 75 上面这段参数的含义: net.ipv4.tcp_keepalive_time 是连接时长，当超过这个时间后，每个 net.ipv4.tcp_keepalive_intvl 的时间间隔会发送keepalive数据包， net.","title":"gRPC Connection reset by peer 问题"},{"content":"   RPC.response.status.code HTTP RPC Description     0 - OK 200 OK Not an error; returned on success.   1 - CANCELLED 499 Client Closed Request The operation was cancelled, typically by the caller.   2 - UNKNOWN 500 Internal Server Error Unknown error. For example, this error may be returned when a Status value received from another address space belongs to an error space that is not known in this address space. Also errors raised by APIs that do not return enough error information may be converted to this error.   3 - INVALID_ARGUMENT 400 Bad Request The client specified an invalid argument. Note that this differs from FAILED_PRECONDITION. INVALID_ARGUMENT indicates arguments that are problematic regardless of the state of the system (e.g., a malformed file name).   4 - DEADLINE_EXCEEDED 504 Gateway Timeout The deadline expired before the operation could complete. For operations that change the state of the system, this error may be returned even if the operation has completed successfully. For example, a successful response from a server could have been delayed long enough for the deadline to expire.   5 - NOT_FOUND 404 Not Found Some requested entity (e.g., file or directory) was not found.Note to server developers: if a request is denied for an entire class of users, such as gradual feature rollout or undocumented whitelist,NOT_FOUND may be used. If a request is denied for some users within a class of users, such as user-based access control, PERMISSION_DENIED must be used.   6 - ALREADY_EXISTS 409 Conflict The entity that a client attempted to create (e.g., file or directory) already exists.   7 - PERMISSION_DENIED 403 Forbidden The caller does not have permission to execute the specified operation. PERMISSION_DENIED must not be used for rejections caused by exhausting some resource (use RESOURCE_EXHAUSTED instead for those errors). PERMISSION_DENIED must not be used if the caller can not be identified (use UNAUTHENTICATED instead for those errors). This error code does not imply the request is valid or the requested entity exists or satisfies other pre-conditions.   8 - RESOURCE_EXHAUSTED 429 Too Many Requests Some resource has been exhausted, perhaps a per-user quota, or perhaps the entire file system is out of space.   9 - FAILED_PRECONDITION 400 Bad Request The operation was rejected because the system is not in a state required for the operation\u0026rsquo;s execution. For example, the directory to be deleted is non-empty, an rmdir operation is applied to a non-directory, etc.Service implementors can use the following guidelines to decide between FAILED_PRECONDITION, ABORTED, and UNAVAILABLE:(a) Use UNAVAILABLE if the client can retry just the failing call.(b) Use ABORTED if the client should retry at a higher level (e.g., when a client-specified test-and-set fails, indicating the client should restart a read-modify-write sequence).(c) Use FAILED_PRECONDITION if the client should not retry until the system state has been explicitly fixed. E.g., if an \u0026ldquo;rmdir\u0026rdquo; fails because the directory is non-empty, FAILED_PRECONDITION should be returned since the client should not retry unless the files are deleted from the directory.   10 - ABORTED 409 Conflict The operation was aborted, typically due to a concurrency issue such as a sequencer check failure or transaction abort.See the guidelines above for deciding between FAILED_PRECONDITION,ABORTED, and UNAVAILABLE.   11 - OUT_OF_RANGE 400 Bad Request The operation was attempted past the valid range. E.g., seeking or reading past end-of-file.Unlike INVALID_ARGUMENT, this error indicates a problem that may be fixed if the system state changes. For example, a 32-bit file system will generate INVALID_ARGUMENT if asked to read at an offset that is not in the range [0,2^32-1], but it will generate OUT_OF_RANGE if asked to read from an offset past the current file size.There is a fair bit of overlap between FAILED_PRECONDITION and OUT_OF_RANGE. We recommend using OUT_OF_RANGE (the more specific error) when it applies so that callers who are iterating through a space can easily look for an OUT_OF_RANGE error to detect when they are done.   12 - UNIMPLEMENTED 501 Not Implemented The operation is not implemented or is not supported/enabled in this service.   13 - INTERNAL 500 Internal Server Error Internal errors. This means that some invariants expected by the underlying system have been broken. This error code is reserved for serious errors.   14 - UNAVAILABLE 503 Service Unavailable The service is currently unavailable. This is most likely a transient condition, which can be corrected by retrying with a backoff.See the guidelines above for deciding between FAILED_PRECONDITION,ABORTED, and UNAVAILABLE.   15 - DATA_LOSS 500 Internal Server Error Unrecoverable data loss or corruption.   16 - UNAUTHENTICATED 401 Unauthorized The request does not have valid authentication credentials for the peration.    ","permalink":"https://blog.lvlv.fun/posts/2019-06-12/","summary":"RPC.response.status.code HTTP RPC Description     0 - OK 200 OK Not an error; returned on success.   1 - CANCELLED 499 Client Closed Request The operation was cancelled, typically by the caller.   2 - UNKNOWN 500 Internal Server Error Unknown error. For example, this error may be returned when a Status value received from another address space belongs to an error space that is not known in this address space.","title":"gRPC error code"},{"content":"Protobuf是什么  Protobuf是一种平台无关、语言无关、可扩展且轻便高效的序列化数据结构的协议，可以用于通信协议和数据存储等。  传输协议 - 如json、XML IDL - 接口描述语言 存储格式 - 序列化压缩后存储到数据库   核心竞争力  向前向后兼容性 - 新老版本兼容，无需考虑版本升级 多语言代码生成 - 支持Java、Python、PHP、Go等编程语言 快\u0026amp;小 - 序列化、反序列化速度快，压缩比优秀    关键技术 varints编码  每个字节使用其中7位保存数字，最高位表示后面是否还有内容 低位在前，高位在后 保留了fixed32和fixed64，用于传递大的正数 int32、int64、unit32、uint64、bool，序列化结果相互兼容，可以修改  zigzag编码  传统上，负数最高位为1，小负数会浪费编码长度 (n\u0026lt;\u0026lt;1)^(n\u0026gt;\u0026gt;31) -1将会被编码成1，1将会编码成2，-2将会被编码成3 sint32和sint64使用zigzag编码  message structure编码  Tag-Value编码 Tag=(field_number\u0026lt;\u0026lt;3)|wire_type-\u0026gt;varints wire_type:0表示varints，1表示固定64位，5表示固定32位 wire_type:2表示Tag-Length-Value编码（TLV），Length使用varints string、bytes、message嵌套，都采用TLV编码  wire_type只有0、1、2、5，那么3和4去哪了？—被废除了\nrepeated编码   第一种方式：重复出现的相同tag\n  第二种方式：(packed=true)，TLVVV…编码\n仅有数字类型才可以使用第二种方法，protocol buffers 3（pb3）中默认第二种，pb2中需要指定，第一种任何情况下会被支持\n非repeated情况出现重复tag，后面的覆盖前面的，因此optional和repeated相互兼容\n  Map编码 map\u0026lt;key_type,value_type\u0026gt;map_field=N\n序列化结果完全等价于：\n1message MapFieldEntry { 2 key_type key = 1; 3 value_type value = 2; 4} 5repeated MapFieldEntry map_field = N; protoc编译器  C++编写的proto文件编译器 支持各种语言编写的插件，使用进程间通信传递信息 Android和iOS上有对应的插件支持，自动调用protoc  Github地址：https://github.com/protocolbuffers/protobuf\n如何使用  命名：message用驼峰，字段用下划线，enum用大写下划线，服务名方法名均为驼峰 无历史包袱，使用proto3，proto2也尽量不要使用required（pb3中被废除） 不要修改旧字段，不要重复使用tag值 为最常用的字段保留1-15序号 与json转换，使用pbjson库  横向对比  JSON：自解释，易读 Thrift：自带rpc方案，跨平台好 MessagePack：可以没有IDL，比JSON快和小 Apache Avro：性能好，hadoop生态中成熟 FlatBuffers：无需反序列化  ","permalink":"https://blog.lvlv.fun/posts/2019-03-14/","summary":"Protobuf是什么  Protobuf是一种平台无关、语言无关、可扩展且轻便高效的序列化数据结构的协议，可以用于通信协议和数据存储等。  传输协议 - 如json、XML IDL - 接口描述语言 存储格式 - 序列化压缩后存储到数据库   核心竞争力  向前向后兼容性 - 新老版本兼容，无需考虑版本升级 多语言代码生成 - 支持Java、Python、PHP、Go等编程语言 快\u0026amp;小 - 序列化、反序列化速度快，压缩比优秀    关键技术 varints编码  每个字节使用其中7位保存数字，最高位表示后面是否还有内容 低位在前，高位在后 保留了fixed32和fixed64，用于传递大的正数 int32、int64、unit32、uint64、bool，序列化结果相互兼容，可以修改  zigzag编码  传统上，负数最高位为1，小负数会浪费编码长度 (n\u0026lt;\u0026lt;1)^(n\u0026gt;\u0026gt;31) -1将会被编码成1，1将会编码成2，-2将会被编码成3 sint32和sint64使用zigzag编码  message structure编码  Tag-Value编码 Tag=(field_number\u0026lt;\u0026lt;3)|wire_type-\u0026gt;varints wire_type:0表示varints，1表示固定64位，5表示固定32位 wire_type:2表示Tag-Length-Value编码（TLV），Length使用varints string、bytes、message嵌套，都采用TLV编码  wire_type只有0、1、2、5，那么3和4去哪了？—被废除了\nrepeated编码   第一种方式：重复出现的相同tag\n  第二种方式：(packed=true)，TLVVV…编码\n仅有数字类型才可以使用第二种方法，protocol buffers 3（pb3）中默认第二种，pb2中需要指定，第一种任何情况下会被支持\n非repeated情况出现重复tag，后面的覆盖前面的，因此optional和repeated相互兼容\n  Map编码 map\u0026lt;key_type,value_type\u0026gt;map_field=N\n序列化结果完全等价于：","title":"Protobuf总结"},{"content":" 作者：Milap Neupane\n链接：https://medium.freecodecamp.org/learning-go-from-zero-to-hero-d2a3223b3d86\n 函数  main.go包中定义的func main()是执行程序的入口。可以定义和使用更多函数。让我们看一个简单的例子：\n1func add(a int, b int) int { 2 c := a + b 3 return c 4} 5func main() { 6 fmt.Println(add(2, 1)) 7} 8// 3  正如我们在上面的例子中所看到的，使用**func关键字后跟函数名来定义Go函数。函数所需的参数**需要根据其数据类型定义，最后是返回的数据类型。\n 函数的返回也可以在函数中预定义：\n1func add(a int, b int) (c int) { 2 c = a + b 3 return 4} 5func main() { 6 fmt.Println(add(2, 1)) 7} 8// 3  这里c被定义为返回变量。因此，定义的变量c将自动返回，而无需在结尾的return语句中定义。\n 还可以从单个函数返回多个返回值，将返回值与逗号分隔开。\n1func add(a int, b int) (int, string) { 2 c := a + b 3 return c, \u0026#34;successfully added\u0026#34; 4} 5func main() { 6 sum, message := add(2, 1) 7 fmt.Println(message) 8 fmt.Println(sum) 9} 结构、方法和接口  Go不是一个完全面向对象的语言，但是它的结构，接口和方法，和面向对象有异曲同工之妙。\n结构  结构struct是不同类型字段的集合。结构用于将数据分组在一起。例如，如果我们想要对Person类型的数据进行分组，我们会定义一个人的属性，其中可能包括姓名，年龄，性别。可以使用以下语法定义结构：\n1type person struct { 2 name string 3 age int 4 gender string 5}  在定义了人类型结构的情况下，现在让我们创建一个person：\n1//方式1：指定属性和值 2p = person{name: \u0026#34;Bob\u0026#34;, age: 42, gender: \u0026#34;Male\u0026#34;} 3//方式2：仅指定值 4person{\u0026#34;Bob\u0026#34;, 42, \u0026#34;Male\u0026#34;}  我们可以用点.轻松访问这些数据\n1p.name 2// Bob 3p.age 4// 42 5p.gender 6// Male  还可以使用其指针直接访问结构的属性：\n1pp = \u0026amp;person{name: \u0026#34;Bob\u0026#34;, age: 42, gender: \u0026#34;Male\u0026#34;} 2pp.name 3// Bob 方法  方法Method是具有接收器的特殊类型的功能*。*接收器既可以是值，也可以是指针。让我们创建一个名为describe的方法，它具有我们在上面的例子中创建的接收器类型：\n1package main 2import \u0026#34;fmt\u0026#34; 3 4// struct defination 5type person struct { 6 name string 7 age int 8 gender string 9} 10 11// method 定义 12func (p *person) describe() { 13 fmt.Printf(\u0026#34;%v is %v years old.\u0026#34;, p.name, p.age) 14} 15func (p *person) setAge(age int) { 16 p.age = age 17} 18 19func (p person) setName(name string) { 20 p.name = name 21} 22 23func main() { 24 pp := \u0026amp;person{name: \u0026#34;Bob\u0026#34;, age: 42, gender: \u0026#34;Male\u0026#34;} 25 pp.describe() 26 // =\u0026gt; Bob is 42 years old 27 pp.setAge(45) 28 fmt.Println(pp.age) 29 // 45 30 pp.setName(\u0026#34;Hari\u0026#34;) 31 fmt.Println(pp.name) 32 // Bob 33}  正如我们在上面的例子中所看到的，现在可以使用点运算符调用该方法pp.describe。请注意，接收器是指针。使用指针，我们传递对值的引用，因此如果我们在方法中进行任何更改，它将反映在接收器pp中。它也不会创建对象的新副本，这样可以节省内存开销。\n 请注意，在上面的示例中，age的值已更改，而name的值未更改，因为方法setName属于接收器类型，而setAge属于指针类型。\n接口  Go接口interface是方法的集合。接口有助于将类型的属性组合在一起。我们以接口animal为例：\n1type animal interface { 2 description() string 3}  这里的animal是一种接口interface类型。现在我们创建两种不同类型的动物来实现animal接口类型：\n1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5) 6 7type animal interface { 8 description() string 9} 10 11type cat struct { 12 Type string 13 Sound string 14} 15 16type snake struct { 17 Type string 18 Poisonous bool 19} 20 21func (s snake) description() string { 22 return fmt.Sprintf(\u0026#34;Poisonous: %v\u0026#34;, s.Poisonous) 23} 24 25func (c cat) description() string { 26 return fmt.Sprintf(\u0026#34;Sound: %v\u0026#34;, c.Sound) 27} 28 29func main() { 30 var a animal 31 a = snake{Poisonous: true} 32 fmt.Println(a.description()) 33 a = cat{Sound: \u0026#34;Meow!!!\u0026#34;} 34 fmt.Println(a.description()) 35} 36 37// Poisonous: true 38// Sound: Meow!!!  在main函数中，我们创建了一个a类型为animal的变量。我们为动物分配蛇和猫类型，并使用Println打印a.description()。由于我们以不同的方式实现了两种类型（猫和蛇）中描述的方法，我们得到了不同动物的属性。\n包  我们在Go中编写所有代码。main包是程序执行的入口点。Go中有很多内置包Package。我们一直使用的就是著名的fmt包。\n  在主要机制中使用Go的包进行大规模编程，可以将大型项目分成更小的部分。\n 安装包 1go get \u0026lt;package-url-github\u0026gt; 2// 示例 3go get github.com/satori/go.uuid  我们安装的软件包保存在GOPATH env中，这是我们的工作目录。通过我们的工作目录中的pkg文件夹进入包cd $GOPATH/pkg。\n创建自定义包  让我们从创建一个文件夹custom_package开始：\n1\u0026gt; mkdir custom_package 2\u0026gt; cd custom_package  要创建自定义包，我们需要先使用我们需要的包名创建一个文件夹。假设我们正在构建一个包person。我们在custom_package目录中创建一个名为person的目录\n1\u0026gt; mkdir person 2\u0026gt; cd person  现在让我们在这个文件夹中创建一个文件person.go。\n1package person 2func Description(name string) string { 3 return \u0026#34;The person name is: \u0026#34; + name 4} 5func secretName(name string) string { 6 return \u0026#34;Do not share\u0026#34; 7}  我们现在需要安装包，以便可以导入和使用它。所以让我们安装它：\n1\u0026gt; go install  现在让我们回到custom_package文件夹并创建一个main.go文件\n1package main 2import( 3 \u0026#34;custom_package/person\u0026#34; 4 \u0026#34;fmt\u0026#34; 5) 6func main(){ 7 p := person.Description(\u0026#34;Milap\u0026#34;) 8 fmt.Println(p) 9} 10// =\u0026gt; The person name is: Milap  现在我们可以导入person我们创建的包并使用函数Description。请注意，secretName我们在包中创建的功能将无法访问。在Go中，以大写字母开头的方法名称将是私有的private。\n包文档  Go内置了对包文档的支持。运行以下命令以生成文档：\n1godoc person Description  这将为我们的包人员生成Description函数的文档。要查看文档，请使用以下命令运行Web服务器：\n1godoc -http=\u0026#34;:8080\u0026#34;  现在转到http://localhost:8080/pkg查看我们刚创建的包的文档。\nGo的内置包 fmt  该包实现了格式化的I/O功能，我们已经使用该包打印出stdout。\njson  Go中另一个有用的包是json包。用于编码/解码JSON。让我们举个例子来编码/解码json：\n 编码\n1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;encoding/json\u0026#34; 6) 7 8func main(){ 9 mapA := map[string]int{\u0026#34;apple\u0026#34;: 5, \u0026#34;lettuce\u0026#34;: 7} 10 mapB, _ := json.Marshal(mapA) 11 fmt.Println(string(mapB)) 12}  解码\n1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;encoding/json\u0026#34; 6) 7 8type response struct { 9 PageNumber int `json:\u0026#34;page\u0026#34;` 10 Fruits []string `json:\u0026#34;fruits\u0026#34;` 11} 12 13func main(){ 14 str := `{\u0026#34;page\u0026#34;: 1, \u0026#34;fruits\u0026#34;: [\u0026#34;apple\u0026#34;, \u0026#34;peach\u0026#34;]}` 15 res := response{} 16 json.Unmarshal([]byte(str), \u0026amp;res) 17 fmt.Println(res.PageNumber) 18} 19// 1  在使用Unmarshal解码json字符串时，第一个参数是json字符串，第二个参数是我们希望json映射到的响应类型struct的地址。请注意，json:\u0026quot;page\u0026quot;映射页面键是结构中的PageNumber键。\n错误处理 Error  错误Error是程序不被希望出现的意外的结果。假设我们正在对外部服务进行API调用，此API调用可能成功也可能失败。当存在错误类型时，我们就可以识别Go程序中的错误。看看下面这个例子：\n1resp, err := http.Get(\u0026#34;http://example.com/\u0026#34;)  这里对错误对象的API调用可能会成功或失败。我们可以检查错误是否为nil，并处理响应：\n1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;net/http\u0026#34; 6) 7 8func main(){ 9 resp, err := http.Get(\u0026#34;http://example.com/\u0026#34;) 10 if err != nil { 11 fmt.Println(err) 12 return 13 } 14 fmt.Println(resp) 15} 自定义错误  当我们编写自己的函数时，有些情况下我们会遇到错误。可以在错误对象的帮助下返回这些错误：\n1func Increment(n int) (int, error) { 2 if n \u0026lt; 0 { 3 // return error object 4 return nil, errors.New(\u0026#34;math: cannot process negative number\u0026#34;) 5 } 6 return (n + 1), nil 7} 8func main() { 9 num := 5 10 11 if inc, err := Increment(num); err != nil { 12 fmt.Printf(\u0026#34;Failed Number: %v, error message: %v\u0026#34;, num, err) 13 }else { 14 fmt.Printf(\u0026#34;Incremented Number: %v\u0026#34;, inc) 15 } 16}  在Go中构建的大多数包或我们使用的外部包都有错误处理机制。所以我们调用的任何函数都可能存在错误。这些错误永远不应该被忽略，并且总是在我们称之为函数的地方优雅地处理，就像我们在上面的例子中所做的那样。\nPanic panic是一种未经处理的事件，在程序执行期间突然遇到。在Go中，panic不是处理程序中异常的理想方式。建议使用错误对象。发生panic时程序会停止执行。panic之后执行的事件就是defer。\nDefer  defer总是在函数结束时执行。\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main() { 6 f() 7 fmt.Println(\u0026#34;Returned normally from f.\u0026#34;) 8} 9 10func f() { 11 defer func() { 12 if r := recover(); r != nil { 13 fmt.Println(\u0026#34;Recovered in f\u0026#34;, r) 14 } 15 }() 16 fmt.Println(\u0026#34;Calling g.\u0026#34;) 17 g(0) 18 fmt.Println(\u0026#34;Returned normally from g.\u0026#34;) 19} 20 21func g(i int) { 22 if i \u0026gt; 3 { 23 fmt.Println(\u0026#34;Panicking!\u0026#34;) 24 panic(fmt.Sprintf(\u0026#34;%v\u0026#34;, i)) 25 } 26 defer fmt.Println(\u0026#34;Defer in g\u0026#34;, i) 27 fmt.Println(\u0026#34;Printing in g\u0026#34;, i) 28 g(i + 1) 29}  在上面的例子中，我们使用panic()来故意终止程序的执行。正如你所注意到的，有一个defer语句，它将使程序在程序执行结束时执行该行。当我们需要在函数结束时执行某些操作时，也可以使用defer，例如关闭文件。\n并发  Go是建立在并发性的基础上的。Go中的并发可以通过轻量级线程的Go例程来实现。\n协程(go routine)  go协程routine是可以与另一个函数并行或同时运行的函数。创建go协程非常简单。只需在函数前面添加关键字go，我们就可以使它并行执行。go协程非常轻量级，因此我们可以创建数千个协程。让我们看一个简单的例子：\n1package main 2import ( 3 \u0026#34;fmt\u0026#34; 4 \u0026#34;time\u0026#34; 5) 6func main() { 7 go c() 8 fmt.Println(\u0026#34;I am main\u0026#34;) 9 time.Sleep(time.Second * 2) 10} 11func c() { 12 time.Sleep(time.Second * 2) 13 fmt.Println(\u0026#34;I am concurrent\u0026#34;) 14} 15// I am main 16// I am concurrent  正如上面的示例，函数c()是一个Go协程，它与主Go线程并行执行。有时我们希望在多个线程之间共享资源。Go更倾向于一个线程的变量不与另一个线程共享，因为这会增加死锁和资源等待的可能性。还有另一种在Go协程之间共享资源的方法：管道Channels。\n管道（channel）  我们可以使用通道在两个Go协程之间传递数据。在创建channel时，必须指定channel接收的数据类型。让我们创建一个字符串类型的简单channel，如下所示：\n1c := make(chan string)  使用此channel，我们可以发送字符串类型数据。可以在此频道中发送和接收数据：\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main(){ 6 c := make(chan string) 7 go func(){ c \u0026lt;- \u0026#34;hello\u0026#34; }() 8 msg := \u0026lt;-c 9 fmt.Println(msg) 10} 11//\u0026#34;hello\u0026#34;  接收方等待发送方向channel发送数据。\n单向通道  在某些情况下，我们希望Go协程通过channel接收数据但不发送数据，反之亦然。为此，我们还可以创建单向通道。让我们看一个简单的例子：\n1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5) 6 7func main() { 8 ch := make(chan string) 9 10 go sc(ch) 11 fmt.Println(\u0026lt;-ch) 12} 13 14func sc(ch chan\u0026lt;- string) { 15 ch \u0026lt;- \u0026#34;hello\u0026#34; 16}  在上面的例子中，sc是一个Go协程，它只能向通道发送消息但不能接收消息。\n使用select为Go例程组织多个通道  函数可能有多个通道正在等待执行。为此，我们可以使用select语句。让我们看一个更清晰的例子：：\n1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;time\u0026#34; 6) 7 8func main() { 9 c1 := make(chan string) 10 c2 := make(chan string) 11 go speed1(c1) 12 go speed2(c2) 13 fmt.Println(\u0026#34;The first to arrive is:\u0026#34;) 14 select { 15 case s1 := \u0026lt;-c1: 16 fmt.Println(s1) 17 case s2 := \u0026lt;-c2: 18 fmt.Println(s2) 19 } 20} 21 22func speed1(ch chan string) { 23 time.Sleep(2 * time.Second) 24 ch \u0026lt;- \u0026#34;speed 1\u0026#34; 25} 26 27func speed2(ch chan string) { 28 time.Sleep(1 * time.Second) 29 ch \u0026lt;- \u0026#34;speed 2\u0026#34; 30}  在上面的示例中，main正在等待两个管道c1和c2。使用select case语句打印主函数，消息从管道发送，无论它先收到哪个。\n缓冲通道  有些情况下我们需要向管道发送多个数据。可以为此创建缓冲通道buffered channel。使用缓冲通道，接收器在缓冲区已满之前不会收到消息。我们来看看这个例子：\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main(){ 6 ch := make(chan string, 2) 7 ch \u0026lt;- \u0026#34;hello\u0026#34; 8 ch \u0026lt;- \u0026#34;world\u0026#34; 9 fmt.Println(\u0026lt;-ch) 10} 结尾 为什么Golang会成功?\n 简单… — Rob-pike\n 目前为止我们已经了解了Go的一些主要组件和功能：\n 变量，数据类型 Array、Slices和Map 函数 循环和条件语句 指针 包 结构、方法和接口 错误处理 并发 - Go routine和channel  恭喜你，你现在对Go有了不错的认识。\n   抛弃了1000行代码的那天是我最富有成效的日子之一。\n                  — Ken Thompson\n 不要止步于此，继续前进。在大脑中思考一个小规模的应用程序并开始构建。\n","permalink":"https://blog.lvlv.fun/posts/2018-12-28/","summary":"作者：Milap Neupane\n链接：https://medium.freecodecamp.org/learning-go-from-zero-to-hero-d2a3223b3d86\n 函数  main.go包中定义的func main()是执行程序的入口。可以定义和使用更多函数。让我们看一个简单的例子：\n1func add(a int, b int) int { 2 c := a + b 3 return c 4} 5func main() { 6 fmt.Println(add(2, 1)) 7} 8// 3  正如我们在上面的例子中所看到的，使用**func关键字后跟函数名来定义Go函数。函数所需的参数**需要根据其数据类型定义，最后是返回的数据类型。\n 函数的返回也可以在函数中预定义：\n1func add(a int, b int) (c int) { 2 c = a + b 3 return 4} 5func main() { 6 fmt.Println(add(2, 1)) 7} 8// 3  这里c被定义为返回变量。因此，定义的变量c将自动返回，而无需在结尾的return语句中定义。\n 还可以从单个函数返回多个返回值，将返回值与逗号分隔开。\n1func add(a int, b int) (int, string) { 2 c := a + b 3 return c, \u0026#34;successfully added\u0026#34; 4} 5func main() { 6 sum, message := add(2, 1) 7 fmt.","title":"learning-go-from-zero-to-hero-part2"},{"content":" 作者：Milap Neupane\n链接：https://medium.freecodecamp.org/learning-go-from-zero-to-hero-d2a3223b3d86\n 开始  想到刚开始学习Go的时候，也是不清不楚地本着拿来能用就行的心态，没有系统学习，导致学习过程中踩坑无数。今天发现一篇文章写的很好，Go语言的特征讲得很细，翻译给需要的初学Go的同学。\n前言  让我们从Go（或者称为Golang）的一个小介绍开始。Go由Google工程师Robert Griesemer，Rob Pike和Ken Thompson设计。它是一种静态类型的编译语言。第一个版本于2012年3月作为开源发布。\n  “ Go是一种开源编程语言，可以轻松构建简单，可靠，高效的软件 ”\n  在许多语言中，有许多方法可以解决给定的问题。程序员可以花很多时间思考解决问题的最佳方法。\n 另一方面，Go相信更少的功能 — 只有一种正确的方法来解决问题。\n 这节省了开发人员的时间，并使大型代码库易于维护。\n  “ 功能越多，成本越高 ” — Rob Pike\n 入门  Go由package组成。名为main的包告诉Go编译器被编译为可执行文件，而不是作为library被引用。它是应用程序的主入口。主包定义为：\n1package main  让我们在Go工作区中创建一个简单的hello world示例。\n工作区  Go中的工作空间由环境变量定义，称为 GOPATH。\n 你的任何代码都将写在工作区内。Go将搜索GOPATH目录中的任何包，或者GOROOT在安装Go时默认设置的目录。注：GOROOT 是安装go的路径。\n 设置GOPATH为所需的目录。现在，让我们将其添加到文件夹中~/workspace。\n1# 定义GOPATH目录 2export GOPATH=~/workspace 3# 进入工作区目录 4cd ~/workspace  在我们刚刚创建的工作区文件夹中创建main.go文件并写入以下代码。\nHello World! 1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5) 6 7func main(){ 8 fmt.Println(\u0026#34;Hello World!\u0026#34;) 9}  在上面的示例中，Go中的官方包fmt实现了格式化I/O的函数。\n 我们使用import 关键字在Go中导入fmt包。func main是代码执行的主入口。Println是fmt包内的一个函数，我们用它来打印“hello world”。\n 让我们先运行这个文件看看。可以通过两种方式运行Go命令。众所周知，Go是编译型语言，所以我们要在执行之前编译它。\n1go build main.go  这将创建一个二进制可执行文件main，现在我们可以运行：\n1./main 2# Hello World！  还有另一种更简单的方式来运行程序。使用go run命令有助于抽象编译步骤。只需运行以下命令即可编译并执行该程序。\n1go run main.go 2# Hello World!  注意： 你可以在 https://play.golang.org/ 练习以上代码\n变量  Go中的变量是明确声明的。Go是一种静态类型语言。这意味着在变量声明时检查变量类型。\n 声明变量方法如下：\n1var a int  在这种情况下，a将自动设默认值为0。\n 使用以下语法声明变量并赋值：\n1var a = 1  这里变量自动指定为int类型。我们可以使用变量声明的简写方式：\n1message := \u0026#34;hello world\u0026#34;  还可以在同一行中声明多个变量：\n1var b, c int = 2, 3 数据类型  与任何其他编程语言一样，Go支持各种不同的数据结构。让我们继续学习：\n数字，字符串和布尔值  Go支持的整数类型包括\n1int, int8, int16, int32, int64,uint, uint8, uint16, uint32, uint64, uintptr ...  字符串类型存储一系列字节。它用关键字string声明\n 布尔值使用关键字bool声明\n Go还支持复数类型数据类型，可以使用complex64和complex128声明。\n1var a bool = true 2var b int = 1 3var c string = \u0026#39;hello world\u0026#39; 4var d float32 = 1.222 5var x complex128 = cmplx.Sqrt(-5 + 12i) Array, Slice, 和 Map  数组array是相同数据类型的元素序列。数组具有在声明中定义的固定长度，因此不能进行扩展。数组声明为：\n1var a [5]int  数组也可以是多维的。我们可以使用以下格式创建多维数组：\n1var multiD [2][3]int  数组的值在运行时无法更改，也不提供获取子数组的能力。为此，Go有一个名为切片slices的数据类型。\n 切片slices存储一系列元素，可以随时扩展。切片声明类似于数组声明\n 未定义容量的slice：\n1var b []int  这将创建一个零容量和零长度的切片。\n 切片也可以定义容量和长度。我们可以使用以下语法：\n1numbers := make([]int,5,10)  上面定义的切片的初始长度为5，容量为10。\n 切片是数组的抽象。切片使用数组作为底层结构。切片包含三个组件：容量，长度和指向底层数组的指针，如下图所示：\n 图片源： https://blog.golang.org/go-slices-usage-and-internals\n 通过使用append()或copy()函数可以增加切片的容量。append函数可以为数组的末尾增加值，并在需要时增加容量：\n1numbers = append(numbers, 1, 2, 3, 4)  增加切片容量的另一种方法是使用copy()函数。只需创建另一个具有更大容量的切片，并将原始切片复制到新创建的切片：\n1// 创建新的切片 2number2 := make([]int, 15) 3// 将原始切片复制到新创建的切片 4copy(number2, number)  我们可以创建切片的子切片。这可以使用以下命令完成：\n1// 声明一个内含{1,2,3,4}共4个元素的切片 2number2 = []int{1,2,3,4} 3fmt.Println(numbers) // -\u0026gt; [1 2 3 4] 4// 创建子切片 5slice1 := number2[2:] 6fmt.Println(slice1) // -\u0026gt; [3 4] 7slice2 := number2[:3] 8fmt.Println(slice2) // -\u0026gt; [1 2 3] 9slice3 := number2[1:4] 10fmt.Println(slice3) // -\u0026gt; [2 3 4]  映射表map是Go中的数据类型，它将键映射到值。我们可以使用以下代码定义键值对映射：\n1var m map[string]int  我们声明了一个名为m的map类型的变量，其键是string类型，值是int类型。我们可以轻松地将键和值添加到map中：\n1// 添加 key/value 2m[\u0026#39;clearity\u0026#39;] = 2 3m[\u0026#39;simplicity\u0026#39;] = 3 4// 打印输出 value 5fmt.Println(m[\u0026#39;clearity\u0026#39;]) // -\u0026gt; 2 6fmt.Println(m[\u0026#39;simplicity\u0026#39;]) // -\u0026gt; 3 类型转换  可以使用类型转换将一种类型的数据类型转换为另一种类型。我们来看一个简单的类型转换：\n1a := 1.1 2b := int(a) 3fmt.Println(b) 4//-\u0026gt; 1  并非所有类型的数据类型都可以转换为其他类型。确保数据类型与转换类型兼容。\n​\n流程控制 if else  我们可以使用if-else语句，如下例所示。确保花括号与条件位于同一行。\n1if num := 9; num \u0026lt; 0 { 2\tfmt.Println(num, \u0026#34;小于0\u0026#34;) 3} else if num \u0026lt; 10 { 4\tfmt.Println(num, \u0026#34;是一位数\u0026#34;) 5} else { 6\tfmt.Println(num, \u0026#34;是多位数\u0026#34;) 7} switch case  switch-case有助于组织多个条件语句。以下实例表示一个简单的switch case语句：\n1i := 2 2switch i { 3\tcase 1: 4\tfmt.Println(\u0026#34;one\u0026#34;) 5\tcase 2: 6\tfmt.Println(\u0026#34;two\u0026#34;) 7\tdefault: 8\tfmt.Println(\u0026#34;none\u0026#34;) 9} 循环  Go使用for来实现不同类型的循环：\n1i := 0 2sum := 0 3for i \u0026lt; 10 { 4\tsum += 1 5\ti++ 6} 7fmt.Println(sum)  上面的示例类似于C中的while循环。对于for循环，还可以使用相同的for语句：\n1sum := 0 2for i := 0; i \u0026lt; 10; i++ { 3\tsum += i 4} 5fmt.Println(sum)  Go中的无限循环：\n1for { 2} 指针  Go提供指针。指针是保存值的内存地址的地方。指针由*定义。\n 根据数据类型定义指针，例如：\n1var ap *int  变量ap是指向整数类型的指针。使用\u0026amp;操作可用于获取变量的地址。\n1a := 12 2ap = \u0026amp;a  可以使用*运算符访问指针指向的值：\n1fmt.Println(*ap) 2// 12  在将结构作为参数传递或者为已定义类型声明方法时，通常首选指针。\n 传递值时，实际复制的值意味着更多的内存 传递指针后，函数更改的值将反映在方法/函数调用者中   例如：\n1func increment(i *int) { 2\t*i++ 3} 4func main() { 5 i := 10 6 increment(\u0026amp;i) 7 fmt.Println(i) 8} 9// 11  注意： 在博客中尝试示例代码时，不要忘记将其包含在main包中，并在需要时导入fmt或其他包，如上面第一个main.go示例所示。\n","permalink":"https://blog.lvlv.fun/posts/2018-12-22/","summary":"作者：Milap Neupane\n链接：https://medium.freecodecamp.org/learning-go-from-zero-to-hero-d2a3223b3d86\n 开始  想到刚开始学习Go的时候，也是不清不楚地本着拿来能用就行的心态，没有系统学习，导致学习过程中踩坑无数。今天发现一篇文章写的很好，Go语言的特征讲得很细，翻译给需要的初学Go的同学。\n前言  让我们从Go（或者称为Golang）的一个小介绍开始。Go由Google工程师Robert Griesemer，Rob Pike和Ken Thompson设计。它是一种静态类型的编译语言。第一个版本于2012年3月作为开源发布。\n  “ Go是一种开源编程语言，可以轻松构建简单，可靠，高效的软件 ”\n  在许多语言中，有许多方法可以解决给定的问题。程序员可以花很多时间思考解决问题的最佳方法。\n 另一方面，Go相信更少的功能 — 只有一种正确的方法来解决问题。\n 这节省了开发人员的时间，并使大型代码库易于维护。\n  “ 功能越多，成本越高 ” — Rob Pike\n 入门  Go由package组成。名为main的包告诉Go编译器被编译为可执行文件，而不是作为library被引用。它是应用程序的主入口。主包定义为：\n1package main  让我们在Go工作区中创建一个简单的hello world示例。\n工作区  Go中的工作空间由环境变量定义，称为 GOPATH。\n 你的任何代码都将写在工作区内。Go将搜索GOPATH目录中的任何包，或者GOROOT在安装Go时默认设置的目录。注：GOROOT 是安装go的路径。\n 设置GOPATH为所需的目录。现在，让我们将其添加到文件夹中~/workspace。\n1# 定义GOPATH目录 2export GOPATH=~/workspace 3# 进入工作区目录 4cd ~/workspace  在我们刚刚创建的工作区文件夹中创建main.go文件并写入以下代码。\nHello World! 1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5) 6 7func main(){ 8 fmt.","title":"learning-go-from-zero-to-hero-part1"}]