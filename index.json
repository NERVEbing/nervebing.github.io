[{"content":"前言 当前越来越多的公司基于 Google gRPC 通信框架来构建微服务体系，比较流行的是使用 Go/Java/C++ 这样的主流编程语言来编写服务端，我们今天来尝试使用 Rust 语言来实现一个 gRPC 服务端/客户端。\n打开官方文档可以看到目前 Rust 并不在 gRPC 官方支持的语言列表中：\n Supported languages\n C# C++ Dart Go Java Kotlin Node Objective-C PHP Python Ruby   不过不用担心这个问题。我们知道只要某个语言兼容了基于 C/C++ 编写的 gRPC 的核心库，那么该语言就可以完美支持 gRPC。目前 Rust 可以实现 gRPC 的主流 crate 如下：\n tonic grpc-rs grpc-rust  以上三种任选其一都可以，只是 grpc-rs/grpc-rust 当前还处于开发状态，我们在这里使用 tonic 包。\n构建程序 首先检查你的 Rust 版本：\n$ rustc --version rustc 1.61.0 (fe5b13d68 2022-05-18) tonic 适用于 1.56 及以上，如果低于这个版本，你应该先更新你的 Rust 编译器：\n$ rustup update stable 确保你已经提前安装了 protobuf：\n$ protoc --version libprotoc 3.19.4  # macOS 可以通过以下命令安装 $ brew install protobuf 使用 cargo 新建一个项目\n$ cargo new grpcrs $ cd grpcrs $ cargo run   Compiling grpcrs v0.1.0 (/Users/lvlv/Documents/project/demo/grpcrs)  Finished dev [unoptimized + debuginfo] target(s) in 0.55s  Running `target/debug/grpcrs` Hello, world! 编辑 cargo.toml 文件：\n[package] name = \u0026#34;grpcrs\u0026#34; version = \u0026#34;0.1.0\u0026#34; edition = \u0026#34;2021\u0026#34;  [[bin]] name = \u0026#34;user-server\u0026#34; path = \u0026#34;src/user/server.rs\u0026#34;  [[bin]] name = \u0026#34;user-client\u0026#34; path = \u0026#34;src/user/client.rs\u0026#34;  [dependencies] tonic = \u0026#34;0.7.2\u0026#34; tokio = { version = \u0026#34;1.18.2\u0026#34;, features = [\u0026#34;macros\u0026#34;, \u0026#34;rt-multi-thread\u0026#34;] } prost = \u0026#34;0.10\u0026#34;  [build-dependencies] tonic-build = \u0026#34;0.7.2\u0026#34; 创建下列文件：\n$ mkdir -p proto/user src/user $ touch build.rs proto/user/user.proto src/user/{server.rs,client.rs} 当前目录结构：\n$ tree -L 3 . ├── Cargo.lock ├── Cargo.toml ├── build.rs # Cargo 构建脚本 ├── proto │ └── user │ └── user.proto # proto 文件 └── src  └── user  ├── client.rs # gRPC 客户端代码  └── server.rs # gRPC 服务端代码 分别将以下内容拷贝到各个文件：\n proto/user/user.proto  syntax = \u0026#34;proto3\u0026#34;;  package user;  service User {  rpc Hello (HelloRequest) returns (HelloReply) {} }  message HelloRequest {  string name = 1; }  message HelloReply {  string message = 1; }  src/user/server.rs  use tonic::{transport::Server, Request, Response, Status};  use user::user_server::{User, UserServer}; use user::{HelloReply, HelloRequest};  pub mod user {  tonic::include_proto!(\u0026#34;user\u0026#34;); }  #[derive(Default)] pub struct UserService {}  #[tonic::async_trait] impl User for UserService {  async fn hello(\u0026amp;self, request: Request\u0026lt;HelloRequest\u0026gt;) -\u0026gt; Result\u0026lt;Response\u0026lt;HelloReply\u0026gt;, Status\u0026gt; {  println!(\u0026#34;New user request from {:?}\u0026#34;, request.remote_addr());   let reply = user::HelloReply {  message: format!(\u0026#34;Hello {}!\u0026#34;, request.into_inner().name),  };  Ok(Response::new(reply))  } }  #[tokio::main] async fn main() -\u0026gt; Result\u0026lt;(), Box\u0026lt;dyn std::error::Error\u0026gt;\u0026gt; {  let addr = \u0026#34;127.0.0.1:50051\u0026#34;.parse().unwrap();  let user_service = UserService::default();   println!(\u0026#34;UserService listening on {}\u0026#34;, addr);   Server::builder()  .add_service(UserServer::new(user_service))  .serve(addr)  .await?;   Ok(()) }  src/user/client.rs  use user::user_client::UserClient; use user::HelloRequest;  pub mod user {  tonic::include_proto!(\u0026#34;user\u0026#34;); }  #[tokio::main] async fn main() -\u0026gt; Result\u0026lt;(), Box\u0026lt;dyn std::error::Error\u0026gt;\u0026gt; {  let mut client = UserClient::connect(\u0026#34;http://127.0.0.1:50051\u0026#34;).await?;   let request = tonic::Request::new(HelloRequest {  name: \u0026#34;Rick\u0026#34;.into(),  });   let response = client.hello(request).await?;   println!(\u0026#34;RESPONSE={:?}\u0026#34;, response);   Ok(()) }  build.rs  use std::{env, path::PathBuf};  fn main() {  let out_dir = PathBuf::from(env::var(\u0026#34;OUT_DIR\u0026#34;).unwrap());   let user_proto = \u0026#34;proto/user/user.proto\u0026#34;;   tonic_build::configure()  .build_server(true)  .build_client(true)  .out_dir(\u0026amp;out_dir)  .file_descriptor_set_path(\u0026amp;out_dir.join(\u0026#34;user_descriptor.bin\u0026#34;))  .compile(\u0026amp;[user_proto], \u0026amp;[\u0026#34;proto\u0026#34;])  .unwrap_or_else(|err| panic!(\u0026#34;protobuf compile failed: {}\u0026#34;, err)); } 尝试编译代码：\n$ cargo build  Compiling proc-macro2 v1.0.39  Compiling unicode-ident v1.0.0  Compiling syn v1.0.95  Compiling libc v0.2.126  Compiling cfg-if v1.0.0  Compiling log v0.4.17  # ... 省略  Compiling hyper v0.14.19  Compiling axum v0.5.6  Compiling hyper-timeout v0.4.1  Compiling tonic v0.7.2  Finished dev [unoptimized + debuginfo] target(s) in 21.01s 如果编译通过，现在我们可以尝试执行编译好的程序了。\n首先启动 gRPC 服务端程序：\n$ cargo run --bin user-server  Finished dev [unoptimized + debuginfo] target(s) in 0.04s  Running `target/debug/user-server` UserService listening on 127.0.0.1:50051 重新打开一个 terminal 窗口并执行客户端程序：\n$ cargo run --bin user-client  Finished dev [unoptimized + debuginfo] target(s) in 0.05s  Running `target/debug/user-client` RESPONSE=Response { metadata: MetadataMap { headers: {\u0026#34;content-type\u0026#34;: \u0026#34;application/grpc\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;Sun, 29 May 2022 21:54:18 GMT\u0026#34;, \u0026#34;grpc-status\u0026#34;: \u0026#34;0\u0026#34;} }, message: HelloReply { message: \u0026#34;Hello Rick!\u0026#34; }, extensions: Extensions } # \u0026lt;- 客户端请求成功并返回响应 此时我们切回服务端 terminal 窗口查看日志：\n# ... UserService listening on 127.0.0.1:50051 New user request from Some(127.0.0.1:52147) # \u0026lt;- 客户端调用成功 至此，一个简单的基于 Rust 的 gRPC 服务端/客户端就实现了。上述代码很简陋，相信只要是接触过 gRPC 的同学都比较容易就可以理解。\n","permalink":"https://lvlv.fun/posts/2022-05-30/","summary":"前言 当前越来越多的公司基于 Google gRPC 通信框架来构建微服务体系，比较流行的是使用 Go/Java/C++ 这样的主流编程语言来编写服务端，我们今天来尝试使用 Rust 语言来实现一个 gRPC 服务端/客户端。\n打开官方文档可以看到目前 Rust 并不在 gRPC 官方支持的语言列表中：\n Supported languages\n C# C++ Dart Go Java Kotlin Node Objective-C PHP Python Ruby   不过不用担心这个问题。我们知道只要某个语言兼容了基于 C/C++ 编写的 gRPC 的核心库，那么该语言就可以完美支持 gRPC。目前 Rust 可以实现 gRPC 的主流 crate 如下：\n tonic grpc-rs grpc-rust  以上三种任选其一都可以，只是 grpc-rs/grpc-rust 当前还处于开发状态，我们在这里使用 tonic 包。\n构建程序 首先检查你的 Rust 版本：\n$ rustc --version rustc 1.61.0 (fe5b13d68 2022-05-18) tonic 适用于 1.56 及以上，如果低于这个版本，你应该先更新你的 Rust 编译器：","title":"使用 Rust 构建 gRPC 微服务"},{"content":"Step 1 登录 Bilibili，点击自己的头像进入个人空间页，点击动态标签。\n此时的 URL 应该是 https://space.bilibili.com/{YOUR_UID}/dynamic。\nStep 2 打开 Chrome 浏览器，按 F12 或手动右键页面，点击检查，切换到控制台标签。\n不支持 Safari。\nStep 3 鼠标移到右上头像，记下当前动态数。\n复制以下代码到 Console 并回车执行，等待 1s，页面应该会自动刷新。\n再次查看右上头像当前动态数，如发现动态数量减少，按方向键上重新调出代码并回车执行，之后复读操作即可。\nconst delBtnElement = \u0026#39;#page-dynamic \u0026gt; div.col-1 \u0026gt; div \u0026gt; div.bili-dyn-list__items \u0026gt; div \u0026gt; div \u0026gt; div \u0026gt; div.bili-dyn-item__header \u0026gt; div.bili-dyn-item__more \u0026gt; div \u0026gt; div \u0026gt; div.bili-dyn-more__menu \u0026gt; div:nth-child(2)\u0026#39; const confirmBtnEliment = \u0026#39;body \u0026gt; div.bili-modal__wrap \u0026gt; div.bili-modal \u0026gt; div.bili-modal__footer \u0026gt; button.bili-modal__button.confirm\u0026#39;  var elements = $(delBtnElement);  if (elements.length == 0) {  throw \u0026#39;当前页面没有可删除的动态\u0026#39;; }  $(delBtnElement).each(  function () {  let text = $(this)[0].innerText;  if (text.indexOf(\u0026#39;删除\u0026#39;) != -1) {  $(this).click();  }  } )  await new Promise(r =\u0026gt; setTimeout(r, 1000));  for (let i = 0; i \u0026lt; elements.length; i++) {  $(confirmBtnEliment).click(); }  location.reload(); ","permalink":"https://lvlv.fun/posts/2022-05-21/","summary":"Step 1 登录 Bilibili，点击自己的头像进入个人空间页，点击动态标签。\n此时的 URL 应该是 https://space.bilibili.com/{YOUR_UID}/dynamic。\nStep 2 打开 Chrome 浏览器，按 F12 或手动右键页面，点击检查，切换到控制台标签。\n不支持 Safari。\nStep 3 鼠标移到右上头像，记下当前动态数。\n复制以下代码到 Console 并回车执行，等待 1s，页面应该会自动刷新。\n再次查看右上头像当前动态数，如发现动态数量减少，按方向键上重新调出代码并回车执行，之后复读操作即可。\nconst delBtnElement = \u0026#39;#page-dynamic \u0026gt; div.col-1 \u0026gt; div \u0026gt; div.bili-dyn-list__items \u0026gt; div \u0026gt; div \u0026gt; div \u0026gt; div.bili-dyn-item__header \u0026gt; div.bili-dyn-item__more \u0026gt; div \u0026gt; div \u0026gt; div.bili-dyn-more__menu \u0026gt; div:nth-child(2)\u0026#39; const confirmBtnEliment = \u0026#39;body \u0026gt; div.bili-modal__wrap \u0026gt; div.bili-modal \u0026gt; div.bili-modal__footer \u0026gt; button.bili-modal__button.confirm\u0026#39;  var elements = $(delBtnElement);  if (elements.","title":"JavaScript 批量删除 Bilibili 动态"},{"content":"前言 声明 本文是个人对 HomeLab 即家庭私有实验室的学习探索，参杂着一些经验总结，记录下来，也希望可以让他人少走一些弯路。\nHomeLab 是什么？ 本质上是一个连接各种设备的复杂系统，你可以用任何树莓派/PC/服务器/路由器组成一个 HomeLab。\nHomeLab 能做什么？  搭建属于私人的网盘，不必在各个设备上安装云盘 App 才能上传/下载文件 不受版权控制的家庭多媒体，集成影视订阅，实现观影追剧自由 集成 HomeBridge 以实现在 iOS/macOS 的 Home.app 中操作非 HomeKit 认证的设备 BT 下载器，无需开启个人电脑，后台下载资源 RSS 订阅器，抛弃无意义地刷手机，只获取自己想要的内容 bilibili/京东每日任务，各种脚本反薅资本家的羊毛 最重要的是你可以搭建包括但不限于 K8S/ELK/MySQL/Redis/Prometheus 等各种服务，也可以在上面跑 CI/CD 自动化构建发布你的代码  阅读门槛  基本的网络知识，比如光猫和路由器的区别，交换机的作用是什么 基本的 Linux 操作，可以理解计算机不是一定要连接显示器才可以操作 遇到问题先使用英文进行 Google，内容过长可以开启页面翻译，请不要看 CSDN 的内容 不求甚解，当你发现你让它跑起来了的时候，会获得极大的心理满足感  设备 架构说明 主要分为服务器和网络设备。考虑到网络设备的稳定性及网络隔离对整套系统的重要程度，没有采用虚拟化 AIO(ALL IN ONE) 方案。\n作为服务端开发者看来所谓的 AIO 毫无稳定性可言，ESXi 的 OpenWrt 虚拟机出了故障会影响其他业务虚拟机的运行，甚至连 iLO 后台都进不去，需要连接显示器手动配置 ESXi 进行修复，这种情况在异地操作 HomeLab 节点的时候是毁灭性的灾难。\n当然这种方式的好处也有：网络上的 教程 较多，按视频操作一步步做几乎没有难点，小白也能轻松搭建。\n缺点就是对整体的 HomeLab 环境一知半解甚至根本不懂，只会复制粘贴。当然你可以说“我只是想快速搭建一整套服务，不想了解细节”，这样的话本文可能不适合你。\n服务器 首先是最重要的服务器部分，绝大多数设备购入时间为 2021年2-3月，价格相比当前可能有很大差距，费用清单如下：\n   设备 价格(元) 数量 备注     HPE Gen10 Plus G5420/8GB 4000 1 淘宝/德国转运   iLO5 NIC Kit 399 1 同上   Intel 志强 E-2146G 1400 1 淘宝/QS版   海力士 32GB DDR4 2666MHz ECC 2600 2 淘宝   希捷 Exos X18 16TB 4200 2 淘宝/国行   英睿达 MX500 SATA SSD 2TB 2400 2 京东自营   三星 PM991 256GB + 佳翼硬盘盒 300 1 PM991闲鱼/硬盘盒京东   三星 850PRO SATA SSD 256G 0 2 家用闲置   Intel 傲腾 NVMe SSD 16GB 0 2 家用闲置   Intel 奔腾 G5420 -488 1 闲鱼出了   HPE 原装海力士 8GB ECC -300 1 闲鱼出了   盈通 GTX1650 4GB DDR6 85 1 1535购入/1450出了   佳翼 NVMe 4X4 阵列卡 1200 1 淘宝   总计 15796      之前没怎么认真统计花费，看到总计后还是惊了一下，老实说这个价格可以上塔式服务器或者洋垃圾 DIY。选择 Gen10 Plus 的理由无外乎精致/美观/静音，毕竟这是一台可以放在卧室的服务器。\n总的来说硬盘/存储占比重较大，当前情况下的配置不是最终配置，目的也仅仅是为了满足个人需求。\n如果能把硬盘换成 SATA SSD 4TB * 4 会更好，当然 NVMe 阵列卡插满4条 m.2 也可，主做 NAS 服务器的话直接更换为 10G/25G/40G 网卡。配置是为了匹配实际用途，否则就是卑鄙的浪费。\n主机 主机从下单到收货前前后后差不多一个月的时间。  开箱，高贵的日耳曼甜美空气扑面而来(doge)。\n  即使在公司加班也阻止不了我欣赏它的美。\n  拧开快拆螺丝，欣赏大厂的工整做工，简直是一件艺术品。\n CPU 首先我们要知道 Gen10 Plus 的 DC 电源是 180W，在官方高配也就是 Intel E-2224/16GB/单SSD 的情况下整机功耗能达到 110W，最多只能留下 70W 的可用空间。考虑到电源转换效率以及需要留点余量(20W)，这样我们可以操作的空间就只剩下 50W。\n每一块希捷 Exos X18 16TB 的待机功耗大概是 5W，满载功耗是 10W，4块满载 40W，这么看来光是硬盘塞满的情况下电源就已经快撑不住了，更别提上个网卡或显卡了。\n然而事实是我们不会让服务器始终跑在 100% 的负载下，也就是说功耗峰值不代表日常功耗。根据我目前的配置，待机功耗在 35W 左右，目前跑了 20+ 个服务的情况下也不过 50W，程序的 CPU 占用率也可以在 docker 命令中加以限制。\n现在我们再来看 CPU 的选择：\n 上图来自 servethehome.com 的 HPE ProLiant MicroServer Gen10 Plus Ultimate Customization Guide 一文，是一篇非常好的 HPE Gen10 Plus 设备选择指导。\n 根据 servethehome.com 的测试结果，当使用 E-2288G/64GB/单SSD 在 Windows Server 2019 上跑 Prime95 时，功率计上的数值达到了 194.5W，所以 8核16线程 直接排除。\n由于跑大量服务需要更多的核心/线程数，并且官方高配就是 4核4线程，所以我们筛选 6核12线程 的 CPU 如下：\n   型号 核心/线程数 频率 TDP(W)     基准 E-2224 4C/4T 3.4-4.6GHz 71W   E-2276G 6C/12T 3.8-4.9GHz 80W   E-2246G 6C/12T 3.6-4.8GHz 80W   E-2236 6C/12T 3.4-4.8GHz 80W   E-2176G 6C/12T 3.7-4.7GHz 80W   E-2146G 6C/12T 3.5-4.5GHz 80W   E-2136 6C/12T 3.3-4.5GHz 80W    最好的选择当然是 E-2276G，但当时 E-22XX 系列太贵了，而且志强8代与9代性能差距不大，所以范围缩小成了 E-2176G、E-2146G、E-2136 三款。\n根据 CPU Benchmarks 的对比结果来看三款在跑分上基本上可以说是没什么差距，由于 E-2146G 相比 E-2136 多了核显，虽然 Gen10 Plus 主板屏蔽了核显，但以后可以等 E-2278G 价格亲民后进行置换，拆下来 E-2146G 可以给别的机器用，所以最终选择了 E-2146G。\n 淘宝 1400 拿下 E-2146G QS 正显，步进和正式版相同 e4，成色相当之好，插上点亮。\n  iLO 中处理器信息一切正常。\n  稍微测了下，睿频 4.5GHz，全核心满载 4.2GHz，此时 CPU 温度 85度 左右，插座显示 120W，对这个结果相当满意。\n 内存 HPE Gen10 Plus 官方产品页上写的最大支持内存是 32GB，实测支持 64GB，且不像 Gen8，Gen10 Plus 支持非 ECC 内存，给预算不充足的玩家留足了余地。\nHPE 的原装内存是海力士的 8GB DDR4 ECC 2666MHz，在奔腾 G5420 下只能以 2400MHz 运行，不多说直接挂闲鱼。\n32GB 纯 ECC 内存的选择有三星和海力士。三星由于贴牌寨条较多，正品库存少不好买，海力士也是 HPE 认证内存厂商，所以选择了后者。\n iLO 内存信息，64GB DDR4 2666MHz ECC，双通道运行。\n  奇怪的是制造商一栏显示不适用，但其他信息完全正常，Reddit 上查到只有官方部件号的 16GB 单条才有制造商信息，无所谓了。\n 硬盘 HDD HDD 选择了两块加拿大白嫖王多次认证的 希捷 Exos X18 16TB，没什么好说的。购入的时候单价 2100(2021.3)，一个月后 Chia 大火价格翻了一倍，目前价格降到了 1800(2022.5) 左右，早知道当时应该出了。\n 出色的稳定性和相对较低的磁盘共振噪音让 Exos X18 依旧相较于 WD Ultrastar DC HC550 来说是更好的选择。\n smartctl -a /dev/sda |grep Temperature_Celsius Temperature_Celsius 33 smartctl -a /dev/sdb |grep Temperature_Celsius Temperature_Celsius 34  日常待机温度也让人相当安心。\n  悲催的是其中一块在插到另一台机器上调试的时候，SATA 接口附近的塑料片被带掉了下来。联系了售后，要上海解封后才能换接口，先用一块三星 850 PRO 256G 做系统盘。\n SSD 既然要跑服务，HDD 的读写速度当然是不够看的。Intel D3-S4610、Intel D3-S4510 等企业级 SSD 除了贵没有任何缺点，但闲鱼上全是高强度锻炼清零盘，实在让人买不下手。\n于是目光转向便宜大碗的京东自营 英睿达 MX500 2TB。\n 刚好有活动单价 1199 拿下，5年质保。英睿达京东自营算是全球指定售后点，出了问题基本上直接换新。\n PCIe PCIe 插槽的选择是最让人纠结的地方，由于 Gen10 Plus 内部只有一个 PCIe 3.0 X16 单槽/半高插槽，能使用的配件主要有下面几个类型：\n 显卡 网卡 SAS卡 PCIe SSD/PCIe 转 NVMe 转接卡  显卡 选择显卡的理由显而易见：可以硬解 Jellyfin/Emby；可以跑 CUDA；可以虚拟化环境中直通到 Windows 打游戏。\n功耗是不得不考虑的问题，PCIe X16 可提供功耗为 70W，高负载模式下对 Gen10 Plus 的供电来说是不小的挑战。\n本人为了硬解视频先后尝试了 Radeon RX550/GeForce GTX 1650，总的来说 ESXi 环境中A卡的兼容性会好一些，但在特定的应用中转换效率较低；N卡(指1650这样的非专业卡)在 ESXi7.0 中的表现极差，费劲直通到 Windows 却做不到持久化，虚拟机重启就会失效，说到底还是 ESXi 对消费级显卡的不兼容，但在纯 docker 环境中N卡的视频解码表现远比A卡要强。\n 上图为盈通 GeForce GTX1650 4GB DDR6，目前 (2022.1) 不用外接电源单槽半高最强显卡，HTPC 最优选择，支持各种视频解码。145mm 全长/纯铜散热片，做工扎实，丽台同款价格 2699，除了 logo 其他完全一样。\n 网卡 由于 2.5G/5G 都可以通过 USB3.0 的方式转换，这里推荐 威联通（QNAP）5G转换器，在 Linux 下也有很好的兼容性。\n10G(万兆) 分为 电口(RJ45) 和 光口(SFP+)，Gen10 Plus 的 PCIe 区域是没有风道的，从功耗和散热来说，光口更值得推荐。如果有主做 NAS 需求的话，推荐 Intel X710-DA4，但记得同时购入光转电模块。\n25G 及以上不在本文讨论范围内。\nSAS卡 除非有非常强烈的硬 RAID 需求，否则不推荐 SAS卡占用唯一的 PCIe 插槽这样的宝贵资源。\nPCIe SSD/PCIe 转 NVMe 转接卡 PCIe SSD 可以选择 Intel DC P3608 或 Intel 傲腾 SSD 905P，但这类企业级 PCIe 太贵了，比较常用的做法是 PCIe 转 NVMe 转接卡类似 佳翼冷雨燕NVMe转接卡 这类经济实惠的方案。\n需要注意的是，如果想要 PCIe 转接多条 m.2 NVMe 的话，需要购买自带主控芯片的拆分卡，我的选择是 佳翼 NVMe阵列卡 4x4 SSD PCIE转M.2转接卡。\n 自带 ASM2824 主控支持拆分，不挑主板，带涡轮风扇。热量主要来自于 SSD 的芯片和主控，加上 PCIe 区域通风不佳，散热只能说马马虎虎，不是这张卡的问题。\n smartctl -a /dev/nvme0n1 |grep Temperature Temperature: 52 Celsius smartctl -a /dev/nvme1n1 |grep Temperature Temperature: 53 Celsius  风扇转速 14% 的情况下，最热的 07-BMC 其实是 iLO 芯片，下面的 10-PCI 1 Zone 在低负载下其实温度还行。\n 网络设备 OpenWrt 比较推荐 J4125 四口 2.5G 软路由，比如 康耐信J4125 I225-V 2.5G 这款，看评测比倍控的方案散热好一些，日后换 2.5G 口的 AP 也比较合适。\n有树莓派的话也可以用树莓派，做个类似这样的方案：\n 树莓派4B + 5口千兆交换机 + USB千兆网卡，小巧又精致。\n 由于老家是老房子，装修的时候还是百兆网线，手头一个 斐讯N1 就够用了。\n固件选择 kiddin9 或者 gd0772。\nWi-Fi Mesh 目前是 红米AX6S + 小米AX1800 组 Mesh，对 Wi-Fi 速率需求没那么高，信号覆盖范围广就可以。\n其他 UPS 不间断电源 UPS 选择的是 APC BK650M2-CH，390W 带 服务器 + 路由器 + 交换机足够用了。\n# apt安装守护进程 sudo apt install -y apcupsd  # 修改配置文件后保存 sudo vim /etc/apcupsd/apcupsd.conf  UPSNAME APC-BK650M2 # 随意修改 UPSCABLE usb UPSTYPE usb DEVICE # 留空  # 重启服务 systemctl restart apcupsd.service  # 查看运行情况 apcaccess  APC : 001,036,0873 DATE : 2022-05-12 15:09:50 +0800 HOSTNAME : lvlv-Gen10Plus VERSION : 3.14.14 (31 May 2016) debian UPSNAME : APC-BK650M2 CABLE : USB Cable DRIVER : USB UPS Driver UPSMODE : Stand Alone STARTTIME: 2022-05-07 09:48:38 +0800 MODEL : Back-UPS BK650M2-CH STATUS : ONLINE LINEV : 235.0 Volts LOADPCT : 13.0 Percent BCHARGE : 100.0 Percent TIMELEFT : 29.9 Minutes MBATTCHG : 5 Percent MINTIMEL : 3 Minutes MAXTIME : 0 Seconds SENSE : Low LOTRANS : 160.0 Volts HITRANS : 278.0 Volts ALARMDEL : 30 Seconds BATTV : 13.5 Volts LASTXFER : No transfers since turnon NUMXFERS : 0 TONBATT : 0 Seconds CUMONBATT: 0 Seconds XOFFBATT : N/A SELFTEST : NG STATFLAG : 0x05000008 SERIALNO : 9B2131A03464 BATTDATE : 2001-01-01 NOMINV : 220 Volts NOMBATTV : 12.0 Volts NOMPOWER : 390 Watts FIRMWARE : 294803G -292804G END APC : 2022-05-12 15:10:03 +0800 ","permalink":"https://lvlv.fun/posts/2022-05-08/","summary":"前言 声明 本文是个人对 HomeLab 即家庭私有实验室的学习探索，参杂着一些经验总结，记录下来，也希望可以让他人少走一些弯路。\nHomeLab 是什么？ 本质上是一个连接各种设备的复杂系统，你可以用任何树莓派/PC/服务器/路由器组成一个 HomeLab。\nHomeLab 能做什么？  搭建属于私人的网盘，不必在各个设备上安装云盘 App 才能上传/下载文件 不受版权控制的家庭多媒体，集成影视订阅，实现观影追剧自由 集成 HomeBridge 以实现在 iOS/macOS 的 Home.app 中操作非 HomeKit 认证的设备 BT 下载器，无需开启个人电脑，后台下载资源 RSS 订阅器，抛弃无意义地刷手机，只获取自己想要的内容 bilibili/京东每日任务，各种脚本反薅资本家的羊毛 最重要的是你可以搭建包括但不限于 K8S/ELK/MySQL/Redis/Prometheus 等各种服务，也可以在上面跑 CI/CD 自动化构建发布你的代码  阅读门槛  基本的网络知识，比如光猫和路由器的区别，交换机的作用是什么 基本的 Linux 操作，可以理解计算机不是一定要连接显示器才可以操作 遇到问题先使用英文进行 Google，内容过长可以开启页面翻译，请不要看 CSDN 的内容 不求甚解，当你发现你让它跑起来了的时候，会获得极大的心理满足感  设备 架构说明 主要分为服务器和网络设备。考虑到网络设备的稳定性及网络隔离对整套系统的重要程度，没有采用虚拟化 AIO(ALL IN ONE) 方案。\n作为服务端开发者看来所谓的 AIO 毫无稳定性可言，ESXi 的 OpenWrt 虚拟机出了故障会影响其他业务虚拟机的运行，甚至连 iLO 后台都进不去，需要连接显示器手动配置 ESXi 进行修复，这种情况在异地操作 HomeLab 节点的时候是毁灭性的灾难。\n当然这种方式的好处也有：网络上的 教程 较多，按视频操作一步步做几乎没有难点，小白也能轻松搭建。","title":"基于 HPE MicroServer Gen10 Plus 的 HomeLab 搭建 - 硬件篇"},{"content":"MySQL存储结构  B-tree 是平衡的多路查找树。 涉及到磁盘的查找需要设法减少磁盘 I/O 次数。 B-tree 就是为解决这个问题而引入的数据结构。   区别于二叉树 b-tree 可以拥有很多个子节点（这个度量被称为「内结点出度」) 我们可以在技术上使 B-tree 的结点大小为磁盘一个页的大小，并且在新建结点时直接申请一个页大小的空间，使得结点的物理存储位置也是在一个页里，这样就能实现存取一个结点只需一次磁盘 I/O 在最坏情况下，B-tree 的一次检索最多需要H（树的高度）次的磁盘 I/O 实际上，为了取得更大的内结点出度，各个数据库一般会采用 B-tree的变种如 B+-tree，B*-tree 来实现索引，比如 MySQL 的存储引擎 InnoDB 就采用 B+-tree 来实现聚簇索引  索引  字符串索引，长度限制 innodb 存储引擎，默认前缀长度最大能支持767字节；而在开启innodb_large_prefix属性值的情况下，最大能支持3072字节 前缀索引，后缀索引，手动md5哈希索引 innode内置哈希 Cardinality 不重复值预估 ，除以记录总数的比例 尽量接近1 索引的价值越大 查询优化器 选择索引时会考虑这个值 oltp olap Online Analytical Processing Online transaction processing  索引细节  单列索引币复合索引在每个数据页存的记录要多，所以查询优化器优先使用单列索引 覆盖索引 数据最小读取单位(索引页？) count(*) 操作，实际会读取辅助索引，避免读取聚合索引 统计操作，覆盖索引的情况下，可以直接查询复合索引(a,b) 中的b index hint 索引提示 use index 只是提示，force index才是强制 multi-range read 优化 从辅助索引筛选完之后，将结果，已主键进行排序，再去读聚合索引下的记录行 index condition pushdown （IPC）优化，将where 过滤条件推送到存储引擎，减少数据传输 (使用时会提示 using index condition) innodb 全文索引 使用倒排索引实现 ，使用了FTS Index Cache 缓存数据变更，批量更新到Auxiliary Table中(这个表可以通过关键词定位到文档，单词位置)  锁   myisam 只支持表锁，sql server 2005版之前只支持页锁，2005开始支持行锁，但是实现方式与innodb不同，加锁会有资源开销，innodb则与oracle 的锁实现类似\n  lock 锁，与latch锁， lock用于事务，latch用于保证并发下的数据一致性（临界资源）\n  查看latch锁 show engine innodb mutex;\n  查看lock 锁 show engine innodb status;\n  共享锁 s Lock，允许事务读一行数据，共享锁可以叠加，称为锁兼容\n  排他锁 x Lock,允许事务删除或者更新一行数据\n  意向锁 (Intention Lock) ,对子级上锁，需要怼父级上意向锁，s锁，对应is,x锁对应ix\n  查看锁的情况，show full processlist,show engine innodb status, information_schema下的，innodb_trx,innodb_locks,innodb_lock_waits 等三张表\n  如果没有合适的索引，则innodb会使用主键来进行锁定(可能会造成表锁)\n  索引含有唯一属性时，where id=1 类似的查询Next-Key Lock 会降级为Record Lock\n  锁的问题   脏读 (read uncommited级别下)脏数据是事务对缓冲池中的行记录的修改，并且没有被提交(commit),脏读就是读到了未提交数据\n  不可重复读 (read commited级别下) 在当前事务两次读取不一致，第二次读到了其他事务提交的数据\n  丢失更新 一个事务的更新，被另外一个事务覆盖，数据库本身不会发生这个错误，程序缓存变量值再写入时可能发生\n  阻塞 innodb 默认不会回滚阻塞超时引发的异常\n  死锁 基础是等待一方超时，innodb还采用 wait-for graph(等待图) 深度优先算法 采用递归实现(innodb 1.2之后采用非递归方式实现递归)\n  发生死锁的因素 1.并发事务数量 2.每个事务操作的数量 3.操作数据的集合大小，集合越大越不容易冲突\n  innodb一般情况出错，不会回滚事务，但是死锁除外，死锁时，innodb会回滚其中一个事务，死锁报错(1213)\n  事务   ACID 原子性(atomicity) 一致性(consistency) 隔离性(isolation) 持久性(durability)\n  事务的分类 扁平事务(Flat Transactions) 带有保存点的扁平事务(Flat Transactions with Savepoints) 链事务(Chained Transactions) 嵌套事务(Nested Transactions) 分布式事务(Distributed Transactions)\n  事务的隔离性由锁来实现\n  事务的原子性，一致性，持久性 通过 redo log和undo log来完成\n  Innodb不支持嵌套事务，当执行一个START TRANSACTION指令时，会隐式的执行一个commit操作。\n  事务控制   innodb默认是自动提交的(auto commit)\n  begin/start transaction 显示的开启事务\n  隐式提交的sql语句:alter 等修改表结构，修改数据库的语句\n  事务操作的统计 com_commit与com_rollback (默认是自动提交autocommit=1,不会记入这两字段) show global status like ‘com_commit’\n  另外两个参数 handler_commit与handle_rollback\n  事务隔离级别\n     隔离级别Isolation Level 脏读Dirty Read 不可重复读NonRepeatable Read 幻读Phantom Read     未提交读Read uncommitted 可能 可能 可能   已提交读Read committed 不可能 可能 可能   可重复读Repeatable read 不可能 不可能 可能   可串行化Serializable 不可能 不可能 不可能     未提交读(Read Uncommitted)：\n允许脏读，也就是可能读取到其他会话中未提交事务修改的数据。\n  已提交读(Read Committed)：\n只能读取到已经提交的数据。Oracle等多数数据库默认都是该级别（不重复读）。\n  可重复读(Repeated Read)：\n可重复读。在同一个事务内的查询都是事务开始时刻一致的，InnoDB默认级别。在SQL标准中，该隔离级别消除了不可重复读，但是还存在幻象读。\n  可串行化(Serializable)：\n完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞，innodb在repeatable read隔离级别下就能达到3度的隔离，所以一般不需要serializable。\n  幻读，并不是说两次读取获取的结果集不同，幻读侧重的方面是某一次的 select 操作得到的结果所表征的数据状态无法支撑后续的业务操作。更为具体一些：select 某记录是否存在，不存在，准备插入此记录，但执行 insert 时发现此记录已存在，无法插入，此时就发生了幻读。\n 分布式事务   innodb 支持XA事务，通过XA事务来支持分布式事务的实现\n  XA事务支持不同数据库之间的分布式事务\n  XA事务由一个或多个资源管理器(Resource Managers),一个事务管理器(Transaction Manager)以及一个应用程序(Application Program)组成\n  资源管理器:提供访问事务资源的方法，通常就是数据库\n  事务管理器:协调参与全局事务中的各个事务 (MySQL服务器的客户端)\n  应用程序:定义事务的边界，指定全局事务中的操作\n  Java的JTA(Java Transaction API)可以很好的支持MySQL的分布式事务\n  MySQL内部也存在另外一种内部XA事务，在存储引擎与插件直接，或者不同存储引擎之间\n  最常见的内部XA事务是binlog与innodb存储引擎之间\n  不好的事务习惯，在循环中提交事务 使用自动提交，使用自动回滚\n  日志   redo log 重做日志 用来保证事务的原子性和持久性， redo log 有单独的文件保存\n  redo log 记录物理修改，某个表空间，某个页，某条记录的值\n  redo log 分为两部分 内存中的 redo log buffer 重做日志文件 redo log file\n  事务提交时，必须将重做日志持久化，才算完成，即每次提交commit,写入重做日志到磁盘后都会调用fsync，强制写入到磁盘，避免停留在文件系统的写入缓冲\n  通过修改配置可以改变重做日志刷新模式， innodb_flush_log_at_trx_commit 默认为1，改为0不写入重做日志，而是等待一个时间周期(1s)后由master thread统一操作，设置为2表示提交时仅写入文件系统缓存\n  innodb_flush_log_at_trx_commit 改为0或2时，对事务性能有明显的提升，但是在特定的条件下会牺牲数据的一致性，即写入到缓存而未刷新到硬盘\n  redo log 以512字节进行存储，以块(block)的方式进行保存， 称为重做块日志 redo log block\n  block 大小与磁盘扇区大小一致，保证写入的原子性，不需要doublewrite技术\n  innodb1.2之前，重做日志总大小要小于4G,innodb1.2开始限制提高到512G\n  重做日志，格式 redo_log_type:重做日志类型 space:表空间id page_no:也的偏移量\n  LSN(Log Sequence Number)日志序列号 含义:1.重做日志写入的字节总量 2.checkpoint的位置 3:页的版本\n  show engine innodb status 可以查看lsn的情况\n  Log sequence number 当前的LSN Log flushed up to 表示刷新到重做日志文件的LSN Pages flushed up to Last checkpoint at 刷新到磁盘的LSN\n  生成环境这几个的值可能不同\n  undo log 用来保证事务的一致性，undo log 默认存放在共享表空间中的undo 段中(undo segment)，innodb1.2开始可以修改配置，存放在单独的文件中\n  undo log 记录逻辑修改，回滚时反向操作\n  mvcc就是通过undo log来实现\n  innodb1.1之前 只有一个rollback segment,每个回滚段记录了1024个undo log segment,所以innodb1.1之前只支持并发1024个事务\n  innodb1.1开始支持最大128个rollback segment 所以支持同时在线事务的数量为128*1024\n  事务提交后不能马上删除undo log，因为可能还有其他事务需要读取事务提交前的行记录版本，由单独的pure线程来判断是否需要最终删除undolog\n  undo 页可以重用\n  History list length 代表undo log的数量，purge 会减少这个数量\n  innodb还不能直接查看undo信息。 innosql对information_schema进行扩展，添加了两张数据字典表来查看undo信息 innodb_trx_rollback_segment,查看rollbacksetment,innodb_trx_undo 记录undo log\n  relay log relay log很多方面都跟binary log差不多，区别是：从服务器I/O线程将主服务器的二进制日志读取过来记录到从服务器本地文件，然后SQL线程会读取relay-log日志的内容并应用到从服务器。\n  group commit 一次fsync确保多个事务日志被写入文件\n  innodb1.2之前开启二进制日志后，group commit会失效，因为开启二进制日志后，为了保证存储引擎层的事务与二进制日志的一致性，必须每个步骤都使用fsync，使用prepare_commit_mutex保证顺序 ** 1) 当事务提交时，Innodb存储引擎进行prepare操作 ** 2) MySQL数据库上层写入二进制日志 (fsync由sync_binlog控制) ** 3) Innodb粗糙你引擎层将日志写入重做日志问的 a)修改内存中事务对应的信息，并且将日志写入重做日志缓冲 b)调用fsync将确保日志都从重做日志缓冲写入磁盘 (fsync由 innodb_flush_log_at_trx_commit参数控制)\n  MySQL5.6实现了BLGC(Binary Log Group Commit) 使得数据库层与innodb存储引擎层都实现了group cimmit ,移除了 prepare_commit_mutex锁，提高了性能\n  二进制日志(binlog) ,用来进行POINT-IN-TIME(PIT)的恢复，以及主从复制(Replication)环境的建立\n  重做日志由innodb产生，二进制日志则是在MySQL数据库层产生,对任何存储引擎都会产生二进制日志\n  二进制日志是逻辑日志，记录的是对应的sql语句，而重做日志是物理格式日志\n  二进制日志是事务提交后一次写入，而重做日志是事务每次操作都写入\n  重做日志是幂等的，二进制日志不是\n  binlog 分为 statement与row两种类型\n  备份与恢复   备份方式 mysqldump,ibbackup,replication,第三方工具:xtrabackup,LVM快照备份\n  热备(Hot Backup) 数据库运行中直接无影响备份 冷备(Cold Backup) 数据库停机时备份，(复制物理文件) 温备 (Warm Backup) 数据库运行中有影响备份，(e.g加全局读锁)\n  逻辑备份，裸文件备份\n  完全备份， 增量备份，MySQL本身没有增量备份，通过二进制日志来完成增量备份(效率很低)，可以使用xtrabackup工具 日志备份 二进制日志文件\n  性能调优   选择64位CPU,64位MySQL\n  内存，在达到MySQL数据本身大小前，内存与性能，线性增加\n  机械硬盘与固态硬盘，不同特性对性能的影响， 机械硬盘，随机读性能差，固态硬盘随机读性能好，但是覆盖更新性能有局限，根据不同硬件情况来调整参数与程序设计\n  合理的设置RAID， 有的RAID卡支持写入缓存，可以很好的提高性能，同时注意需要内置UPS电源才能避免数据丢失\n  部分文件系统支持文件快照\n  不同操作系统对MySQL有不同的影响\n  选择合适的基准测试工具sysbench ,mysql-tpcc\n  ","permalink":"https://lvlv.fun/posts/2019-10-29/","summary":"MySQL存储结构  B-tree 是平衡的多路查找树。 涉及到磁盘的查找需要设法减少磁盘 I/O 次数。 B-tree 就是为解决这个问题而引入的数据结构。   区别于二叉树 b-tree 可以拥有很多个子节点（这个度量被称为「内结点出度」) 我们可以在技术上使 B-tree 的结点大小为磁盘一个页的大小，并且在新建结点时直接申请一个页大小的空间，使得结点的物理存储位置也是在一个页里，这样就能实现存取一个结点只需一次磁盘 I/O 在最坏情况下，B-tree 的一次检索最多需要H（树的高度）次的磁盘 I/O 实际上，为了取得更大的内结点出度，各个数据库一般会采用 B-tree的变种如 B+-tree，B*-tree 来实现索引，比如 MySQL 的存储引擎 InnoDB 就采用 B+-tree 来实现聚簇索引  索引  字符串索引，长度限制 innodb 存储引擎，默认前缀长度最大能支持767字节；而在开启innodb_large_prefix属性值的情况下，最大能支持3072字节 前缀索引，后缀索引，手动md5哈希索引 innode内置哈希 Cardinality 不重复值预估 ，除以记录总数的比例 尽量接近1 索引的价值越大 查询优化器 选择索引时会考虑这个值 oltp olap Online Analytical Processing Online transaction processing  索引细节  单列索引币复合索引在每个数据页存的记录要多，所以查询优化器优先使用单列索引 覆盖索引 数据最小读取单位(索引页？) count(*) 操作，实际会读取辅助索引，避免读取聚合索引 统计操作，覆盖索引的情况下，可以直接查询复合索引(a,b) 中的b index hint 索引提示 use index 只是提示，force index才是强制 multi-range read 优化 从辅助索引筛选完之后，将结果，已主键进行排序，再去读聚合索引下的记录行 index condition pushdown （IPC）优化，将where 过滤条件推送到存储引擎，减少数据传输 (使用时会提示 using index condition) innodb 全文索引 使用倒排索引实现 ，使用了FTS Index Cache 缓存数据变更，批量更新到Auxiliary Table中(这个表可以通过关键词定位到文档，单词位置)  锁   myisam 只支持表锁，sql server 2005版之前只支持页锁，2005开始支持行锁，但是实现方式与innodb不同，加锁会有资源开销，innodb则与oracle 的锁实现类似","title":"MySQL/innoDB 内部实现"},{"content":"前提 因产品需求，需用PHP（v7.0.12）调用k8s集群中gRPC（golang@1.12.0）服务。\n问题 经过dev环境测试，当php-fpm启动后第一次调用或者距离上次调用时间20分钟后左右，再次请求gRPC微服务接口，就会返回 Connection reset by peer 错误，说明gRPC服务端或者客户端主动关闭连接了。继续发起请求到服务端，又恢复正常。\n思考 经查阅相关资料，发现问题可能出现在k8s集群的kube-proxy模式上。当前k8s环境(dev)下的kube-proxy为ipvs模式，服务端与客户端之间通信如下：\n把上图client看成是apsopen-inside服务pod，Backend pod(1~3)看成gRPC服务，可以看出它们之间的交互路径：\n ---\u0026gt; gRPC server pod1 gRPC-client ---\u0026gt; ipvs ---\u0026gt; gRPC server pod3  ---\u0026gt; gRPC server pod3 我们知道gRPC是基于HTTP/2协议的，gRPC的client和server在交互时会建立多条连接，为了性能，这些连接都是长连接并且是一直保活的。 这段环境中不管是客户端服务还是gRPC服务都被调度到各个相同配置信息的Kubernetes节点上，这些k8s节点的 keep-alive 是一致的，如果出现连接主动关闭的问题，因为从client到server经历了一层ipvs，所以最大的可能就是ipvs出将连接主动断开，而client端还不知情。 搜索 ipvs timeout 关键字找到了下面相关的链接：\n https://github.com/moby/moby/issues/31208 https://success.docker.com/article/ipvs-connection-timeout-issue https://github.com/kubernetes/kubernetes/issues/32457  其中 https://github.com/moby/moby/issues/31208 中是关于docker swarm在overlay网络下长连接的问题，这个和k8s kube-proxy应该是类似的，按照这个链接中的描述查看 我们这套环境关于tcp keepalive的内核参数：\n#进入igo-util-shorturi容器  sysctl net.ipv4.tcp_keepalive_time net.ipv4.tcp_keepalive_probes net.ipv4.tcp_keepalive_intvl net.ipv4.tcp_keepalive_time = 7200 net.ipv4.tcp_keepalive_probes = 9 net.ipv4.tcp_keepalive_intvl = 75 上面这段参数的含义: net.ipv4.tcp_keepalive_time 是连接时长，当超过这个时间后，每个 net.ipv4.tcp_keepalive_intvl 的时间间隔会发送keepalive数据包， net.ipv4.tcp_keepalive_probe 是发送keepalived数据包的频率。\n解决 使用 ipvsadm 命令查看k8s节点上ipvs的超时时间：\nipvsadm -l --timeout Timeout (tcp tcpfin udp): 900 120 300 可以看出，各个k8s节点上tcp keepalive超时是7200秒(即2小时)，ipvs超时是900秒(15分钟)，这就出现如果客户端或服务端在15分钟内没有应答时，ipvs会主动将tcp连接终止，而客户端还以为超时间依然是2个小时。 很明显 net.ipv4.tcp_keepalive_time 不能超过ipvs的超时时间。\n调节k8s节点上的tcp keepalive参数如下：\nnet.ipv4.tcp_keepalive_time = 600 net.ipv4.tcp_keepalive_intvl = 30 net.ipv4.tcp_keepalive_probes = 10 再去测试Connection reset by peer问题已经解决。\n","permalink":"https://lvlv.fun/posts/2019-07-22/","summary":"前提 因产品需求，需用PHP（v7.0.12）调用k8s集群中gRPC（golang@1.12.0）服务。\n问题 经过dev环境测试，当php-fpm启动后第一次调用或者距离上次调用时间20分钟后左右，再次请求gRPC微服务接口，就会返回 Connection reset by peer 错误，说明gRPC服务端或者客户端主动关闭连接了。继续发起请求到服务端，又恢复正常。\n思考 经查阅相关资料，发现问题可能出现在k8s集群的kube-proxy模式上。当前k8s环境(dev)下的kube-proxy为ipvs模式，服务端与客户端之间通信如下：\n把上图client看成是apsopen-inside服务pod，Backend pod(1~3)看成gRPC服务，可以看出它们之间的交互路径：\n ---\u0026gt; gRPC server pod1 gRPC-client ---\u0026gt; ipvs ---\u0026gt; gRPC server pod3  ---\u0026gt; gRPC server pod3 我们知道gRPC是基于HTTP/2协议的，gRPC的client和server在交互时会建立多条连接，为了性能，这些连接都是长连接并且是一直保活的。 这段环境中不管是客户端服务还是gRPC服务都被调度到各个相同配置信息的Kubernetes节点上，这些k8s节点的 keep-alive 是一致的，如果出现连接主动关闭的问题，因为从client到server经历了一层ipvs，所以最大的可能就是ipvs出将连接主动断开，而client端还不知情。 搜索 ipvs timeout 关键字找到了下面相关的链接：\n https://github.com/moby/moby/issues/31208 https://success.docker.com/article/ipvs-connection-timeout-issue https://github.com/kubernetes/kubernetes/issues/32457  其中 https://github.com/moby/moby/issues/31208 中是关于docker swarm在overlay网络下长连接的问题，这个和k8s kube-proxy应该是类似的，按照这个链接中的描述查看 我们这套环境关于tcp keepalive的内核参数：\n#进入igo-util-shorturi容器  sysctl net.ipv4.tcp_keepalive_time net.ipv4.tcp_keepalive_probes net.ipv4.tcp_keepalive_intvl net.ipv4.tcp_keepalive_time = 7200 net.ipv4.tcp_keepalive_probes = 9 net.ipv4.tcp_keepalive_intvl = 75 上面这段参数的含义: net.ipv4.tcp_keepalive_time 是连接时长，当超过这个时间后，每个 net.ipv4.tcp_keepalive_intvl 的时间间隔会发送keepalive数据包， net.","title":"gRPC Connection reset by peer 问题"},{"content":"   RPC.response.status.code HTTP RPC Description     0 - OK 200 OK Not an error; returned on success.   1 - CANCELLED 499 Client Closed Request The operation was cancelled, typically by the caller.   2 - UNKNOWN 500 Internal Server Error Unknown error. For example, this error may be returned when a Status value received from another address space belongs to an error space that is not known in this address space. Also errors raised by APIs that do not return enough error information may be converted to this error.   3 - INVALID_ARGUMENT 400 Bad Request The client specified an invalid argument. Note that this differs from FAILED_PRECONDITION. INVALID_ARGUMENT indicates arguments that are problematic regardless of the state of the system (e.g., a malformed file name).   4 - DEADLINE_EXCEEDED 504 Gateway Timeout The deadline expired before the operation could complete. For operations that change the state of the system, this error may be returned even if the operation has completed successfully. For example, a successful response from a server could have been delayed long enough for the deadline to expire.   5 - NOT_FOUND 404 Not Found Some requested entity (e.g., file or directory) was not found.Note to server developers: if a request is denied for an entire class of users, such as gradual feature rollout or undocumented whitelist,NOT_FOUND may be used. If a request is denied for some users within a class of users, such as user-based access control, PERMISSION_DENIED must be used.   6 - ALREADY_EXISTS 409 Conflict The entity that a client attempted to create (e.g., file or directory) already exists.   7 - PERMISSION_DENIED 403 Forbidden The caller does not have permission to execute the specified operation. PERMISSION_DENIED must not be used for rejections caused by exhausting some resource (use RESOURCE_EXHAUSTED instead for those errors). PERMISSION_DENIED must not be used if the caller can not be identified (use UNAUTHENTICATED instead for those errors). This error code does not imply the request is valid or the requested entity exists or satisfies other pre-conditions.   8 - RESOURCE_EXHAUSTED 429 Too Many Requests Some resource has been exhausted, perhaps a per-user quota, or perhaps the entire file system is out of space.   9 - FAILED_PRECONDITION 400 Bad Request The operation was rejected because the system is not in a state required for the operation\u0026rsquo;s execution. For example, the directory to be deleted is non-empty, an rmdir operation is applied to a non-directory, etc.Service implementors can use the following guidelines to decide between FAILED_PRECONDITION, ABORTED, and UNAVAILABLE:(a) Use UNAVAILABLE if the client can retry just the failing call.(b) Use ABORTED if the client should retry at a higher level (e.g., when a client-specified test-and-set fails, indicating the client should restart a read-modify-write sequence).(c) Use FAILED_PRECONDITION if the client should not retry until the system state has been explicitly fixed. E.g., if an \u0026ldquo;rmdir\u0026rdquo; fails because the directory is non-empty, FAILED_PRECONDITION should be returned since the client should not retry unless the files are deleted from the directory.   10 - ABORTED 409 Conflict The operation was aborted, typically due to a concurrency issue such as a sequencer check failure or transaction abort.See the guidelines above for deciding between FAILED_PRECONDITION,ABORTED, and UNAVAILABLE.   11 - OUT_OF_RANGE 400 Bad Request The operation was attempted past the valid range. E.g., seeking or reading past end-of-file.Unlike INVALID_ARGUMENT, this error indicates a problem that may be fixed if the system state changes. For example, a 32-bit file system will generate INVALID_ARGUMENT if asked to read at an offset that is not in the range [0,2^32-1], but it will generate OUT_OF_RANGE if asked to read from an offset past the current file size.There is a fair bit of overlap between FAILED_PRECONDITION and OUT_OF_RANGE. We recommend using OUT_OF_RANGE (the more specific error) when it applies so that callers who are iterating through a space can easily look for an OUT_OF_RANGE error to detect when they are done.   12 - UNIMPLEMENTED 501 Not Implemented The operation is not implemented or is not supported/enabled in this service.   13 - INTERNAL 500 Internal Server Error Internal errors. This means that some invariants expected by the underlying system have been broken. This error code is reserved for serious errors.   14 - UNAVAILABLE 503 Service Unavailable The service is currently unavailable. This is most likely a transient condition, which can be corrected by retrying with a backoff.See the guidelines above for deciding between FAILED_PRECONDITION,ABORTED, and UNAVAILABLE.   15 - DATA_LOSS 500 Internal Server Error Unrecoverable data loss or corruption.   16 - UNAUTHENTICATED 401 Unauthorized The request does not have valid authentication credentials for the peration.    ","permalink":"https://lvlv.fun/posts/2019-06-12/","summary":"RPC.response.status.code HTTP RPC Description     0 - OK 200 OK Not an error; returned on success.   1 - CANCELLED 499 Client Closed Request The operation was cancelled, typically by the caller.   2 - UNKNOWN 500 Internal Server Error Unknown error. For example, this error may be returned when a Status value received from another address space belongs to an error space that is not known in this address space.","title":"gRPC error code"},{"content":"Protobuf是什么  Protobuf是一种平台无关、语言无关、可扩展且轻便高效的序列化数据结构的协议，可以用于通信协议和数据存储等。  传输协议 - 如json、XML IDL - 接口描述语言 存储格式 - 序列化压缩后存储到数据库   核心竞争力  向前向后兼容性 - 新老版本兼容，无需考虑版本升级 多语言代码生成 - 支持Java、Python、PHP、Go等编程语言 快\u0026amp;小 - 序列化、反序列化速度快，压缩比优秀    关键技术 varints编码  每个字节使用其中7位保存数字，最高位表示后面是否还有内容 低位在前，高位在后 保留了fixed32和fixed64，用于传递大的正数 int32、int64、unit32、uint64、bool，序列化结果相互兼容，可以修改  zigzag编码  传统上，负数最高位为1，小负数会浪费编码长度 (n\u0026lt;\u0026lt;1)^(n\u0026gt;\u0026gt;31) -1将会被编码成1，1将会编码成2，-2将会被编码成3 sint32和sint64使用zigzag编码  message structure编码  Tag-Value编码 Tag=(field_number\u0026lt;\u0026lt;3)|wire_type-\u0026gt;varints wire_type:0表示varints，1表示固定64位，5表示固定32位 wire_type:2表示Tag-Length-Value编码（TLV），Length使用varints string、bytes、message嵌套，都采用TLV编码  wire_type只有0、1、2、5，那么3和4去哪了？—被废除了\nrepeated编码   第一种方式：重复出现的相同tag\n  第二种方式：(packed=true)，TLVVV…编码\n仅有数字类型才可以使用第二种方法，protocol buffers 3（pb3）中默认第二种，pb2中需要指定，第一种任何情况下会被支持\n非repeated情况出现重复tag，后面的覆盖前面的，因此optional和repeated相互兼容\n  Map编码 map\u0026lt;key_type,value_type\u0026gt;map_field=N\n序列化结果完全等价于：\nmessage MapFieldEntry {  key_type key = 1;  value_type value = 2; } repeated MapFieldEntry map_field = N; protoc编译器  C++编写的proto文件编译器 支持各种语言编写的插件，使用进程间通信传递信息 Android和iOS上有对应的插件支持，自动调用protoc  Github地址：https://github.com/protocolbuffers/protobuf\n如何使用  命名：message用驼峰，字段用下划线，enum用大写下划线，服务名方法名均为驼峰 无历史包袱，使用proto3，proto2也尽量不要使用required（pb3中被废除） 不要修改旧字段，不要重复使用tag值 为最常用的字段保留1-15序号 与json转换，使用pbjson库  横向对比  JSON：自解释，易读 Thrift：自带rpc方案，跨平台好 MessagePack：可以没有IDL，比JSON快和小 Apache Avro：性能好，hadoop生态中成熟 FlatBuffers：无需反序列化  ","permalink":"https://lvlv.fun/posts/2019-03-14/","summary":"Protobuf是什么  Protobuf是一种平台无关、语言无关、可扩展且轻便高效的序列化数据结构的协议，可以用于通信协议和数据存储等。  传输协议 - 如json、XML IDL - 接口描述语言 存储格式 - 序列化压缩后存储到数据库   核心竞争力  向前向后兼容性 - 新老版本兼容，无需考虑版本升级 多语言代码生成 - 支持Java、Python、PHP、Go等编程语言 快\u0026amp;小 - 序列化、反序列化速度快，压缩比优秀    关键技术 varints编码  每个字节使用其中7位保存数字，最高位表示后面是否还有内容 低位在前，高位在后 保留了fixed32和fixed64，用于传递大的正数 int32、int64、unit32、uint64、bool，序列化结果相互兼容，可以修改  zigzag编码  传统上，负数最高位为1，小负数会浪费编码长度 (n\u0026lt;\u0026lt;1)^(n\u0026gt;\u0026gt;31) -1将会被编码成1，1将会编码成2，-2将会被编码成3 sint32和sint64使用zigzag编码  message structure编码  Tag-Value编码 Tag=(field_number\u0026lt;\u0026lt;3)|wire_type-\u0026gt;varints wire_type:0表示varints，1表示固定64位，5表示固定32位 wire_type:2表示Tag-Length-Value编码（TLV），Length使用varints string、bytes、message嵌套，都采用TLV编码  wire_type只有0、1、2、5，那么3和4去哪了？—被废除了\nrepeated编码   第一种方式：重复出现的相同tag\n  第二种方式：(packed=true)，TLVVV…编码\n仅有数字类型才可以使用第二种方法，protocol buffers 3（pb3）中默认第二种，pb2中需要指定，第一种任何情况下会被支持\n非repeated情况出现重复tag，后面的覆盖前面的，因此optional和repeated相互兼容\n  Map编码 map\u0026lt;key_type,value_type\u0026gt;map_field=N\n序列化结果完全等价于：","title":"Protobuf 总结"},{"content":" 作者：Milap Neupane\n链接：https://medium.freecodecamp.org/learning-go-from-zero-to-hero-d2a3223b3d86\n 函数  main.go包中定义的func main()是执行程序的入口。可以定义和使用更多函数。让我们看一个简单的例子：\nfunc add(a int, b int) int {  c := a + b  return c } func main() {  fmt.Println(add(2, 1)) } // 3  正如我们在上面的例子中所看到的，使用**func关键字后跟函数名来定义Go函数。函数所需的参数**需要根据其数据类型定义，最后是返回的数据类型。\n 函数的返回也可以在函数中预定义：\nfunc add(a int, b int) (c int) {  c = a + b  return } func main() {  fmt.Println(add(2, 1)) } // 3  这里c被定义为返回变量。因此，定义的变量c将自动返回，而无需在结尾的return语句中定义。\n 还可以从单个函数返回多个返回值，将返回值与逗号分隔开。\nfunc add(a int, b int) (int, string) {  c := a + b  return c, \u0026#34;successfully added\u0026#34; } func main() {  sum, message := add(2, 1)  fmt.Println(message)  fmt.Println(sum) } 结构、方法和接口  Go不是一个完全面向对象的语言，但是它的结构，接口和方法，和面向对象有异曲同工之妙。\n结构  结构struct是不同类型字段的集合。结构用于将数据分组在一起。例如，如果我们想要对Person类型的数据进行分组，我们会定义一个人的属性，其中可能包括姓名，年龄，性别。可以使用以下语法定义结构：\ntype person struct {  name string  age int  gender string }  在定义了人类型结构的情况下，现在让我们创建一个person：\n//方式1：指定属性和值 p = person{name: \u0026#34;Bob\u0026#34;, age: 42, gender: \u0026#34;Male\u0026#34;} //方式2：仅指定值 person{\u0026#34;Bob\u0026#34;, 42, \u0026#34;Male\u0026#34;}  我们可以用点.轻松访问这些数据\np.name // Bob p.age // 42 p.gender // Male  还可以使用其指针直接访问结构的属性：\npp = \u0026amp;person{name: \u0026#34;Bob\u0026#34;, age: 42, gender: \u0026#34;Male\u0026#34;} pp.name // Bob 方法  方法Method是具有接收器的特殊类型的功能*。*接收器既可以是值，也可以是指针。让我们创建一个名为describe的方法，它具有我们在上面的例子中创建的接收器类型：\npackage main import \u0026#34;fmt\u0026#34;  // struct defination type person struct {  name string  age int  gender string }  // method 定义 func (p *person) describe() {  fmt.Printf(\u0026#34;%v is %v years old.\u0026#34;, p.name, p.age) } func (p *person) setAge(age int) {  p.age = age }  func (p person) setName(name string) {  p.name = name }  func main() {  pp := \u0026amp;person{name: \u0026#34;Bob\u0026#34;, age: 42, gender: \u0026#34;Male\u0026#34;}  pp.describe()  // =\u0026gt; Bob is 42 years old  pp.setAge(45)  fmt.Println(pp.age)  // 45  pp.setName(\u0026#34;Hari\u0026#34;)  fmt.Println(pp.name)  // Bob }  正如我们在上面的例子中所看到的，现在可以使用点运算符调用该方法pp.describe。请注意，接收器是指针。使用指针，我们传递对值的引用，因此如果我们在方法中进行任何更改，它将反映在接收器pp中。它也不会创建对象的新副本，这样可以节省内存开销。\n 请注意，在上面的示例中，age的值已更改，而name的值未更改，因为方法setName属于接收器类型，而setAge属于指针类型。\n接口  Go接口interface是方法的集合。接口有助于将类型的属性组合在一起。我们以接口animal为例：\ntype animal interface {  description() string }  这里的animal是一种接口interface类型。现在我们创建两种不同类型的动物来实现animal接口类型：\npackage main  import (  \u0026#34;fmt\u0026#34; )  type animal interface {  description() string }  type cat struct {  Type string  Sound string }  type snake struct {  Type string  Poisonous bool }  func (s snake) description() string {  return fmt.Sprintf(\u0026#34;Poisonous: %v\u0026#34;, s.Poisonous) }  func (c cat) description() string {  return fmt.Sprintf(\u0026#34;Sound: %v\u0026#34;, c.Sound) }  func main() {  var a animal  a = snake{Poisonous: true}  fmt.Println(a.description())  a = cat{Sound: \u0026#34;Meow!!!\u0026#34;}  fmt.Println(a.description()) }  // Poisonous: true // Sound: Meow!!!  在main函数中，我们创建了一个a类型为animal的变量。我们为动物分配蛇和猫类型，并使用Println打印a.description()。由于我们以不同的方式实现了两种类型（猫和蛇）中描述的方法，我们得到了不同动物的属性。\n包  我们在Go中编写所有代码。main包是程序执行的入口点。Go中有很多内置包Package。我们一直使用的就是著名的fmt包。\n  在主要机制中使用Go的包进行大规模编程，可以将大型项目分成更小的部分。\n 安装包 go get \u0026lt;package-url-github\u0026gt; // 示例 go get github.com/satori/go.uuid  我们安装的软件包保存在GOPATH env中，这是我们的工作目录。通过我们的工作目录中的pkg文件夹进入包cd $GOPATH/pkg。\n创建自定义包  让我们从创建一个文件夹custom_package开始：\n\u0026gt; mkdir custom_package \u0026gt; cd custom_package  要创建自定义包，我们需要先使用我们需要的包名创建一个文件夹。假设我们正在构建一个包person。我们在custom_package目录中创建一个名为person的目录\n\u0026gt; mkdir person \u0026gt; cd person  现在让我们在这个文件夹中创建一个文件person.go。\npackage person func Description(name string) string {  return \u0026#34;The person name is: \u0026#34; + name } func secretName(name string) string {  return \u0026#34;Do not share\u0026#34; }  我们现在需要安装包，以便可以导入和使用它。所以让我们安装它：\n\u0026gt; go install  现在让我们回到custom_package文件夹并创建一个main.go文件\npackage main import(  \u0026#34;custom_package/person\u0026#34;  \u0026#34;fmt\u0026#34; ) func main(){  p := person.Description(\u0026#34;Milap\u0026#34;)  fmt.Println(p) } // =\u0026gt; The person name is: Milap  现在我们可以导入person我们创建的包并使用函数Description。请注意，secretName我们在包中创建的功能将无法访问。在Go中，以大写字母开头的方法名称将是私有的private。\n包文档  Go内置了对包文档的支持。运行以下命令以生成文档：\ngodoc person Description  这将为我们的包人员生成Description函数的文档。要查看文档，请使用以下命令运行Web服务器：\ngodoc -http=\u0026#34;:8080\u0026#34;  现在转到http://localhost:8080/pkg查看我们刚创建的包的文档。\nGo的内置包 fmt  该包实现了格式化的I/O功能，我们已经使用该包打印出stdout。\njson  Go中另一个有用的包是json包。用于编码/解码JSON。让我们举个例子来编码/解码json：\n 编码\npackage main  import (  \u0026#34;fmt\u0026#34;  \u0026#34;encoding/json\u0026#34; )  func main(){  mapA := map[string]int{\u0026#34;apple\u0026#34;: 5, \u0026#34;lettuce\u0026#34;: 7}  mapB, _ := json.Marshal(mapA)  fmt.Println(string(mapB)) }  解码\npackage main  import (  \u0026#34;fmt\u0026#34;  \u0026#34;encoding/json\u0026#34; )  type response struct {  PageNumber int `json:\u0026#34;page\u0026#34;`  Fruits []string `json:\u0026#34;fruits\u0026#34;` }  func main(){  str := `{\u0026#34;page\u0026#34;: 1, \u0026#34;fruits\u0026#34;: [\u0026#34;apple\u0026#34;, \u0026#34;peach\u0026#34;]}`  res := response{}  json.Unmarshal([]byte(str), \u0026amp;res)  fmt.Println(res.PageNumber) } // 1  在使用Unmarshal解码json字符串时，第一个参数是json字符串，第二个参数是我们希望json映射到的响应类型struct的地址。请注意，json:\u0026quot;page\u0026quot;映射页面键是结构中的PageNumber键。\n错误处理 Error  错误Error是程序不被希望出现的意外的结果。假设我们正在对外部服务进行API调用，此API调用可能成功也可能失败。当存在错误类型时，我们就可以识别Go程序中的错误。看看下面这个例子：\nresp, err := http.Get(\u0026#34;http://example.com/\u0026#34;)  这里对错误对象的API调用可能会成功或失败。我们可以检查错误是否为nil，并处理响应：\npackage main  import (  \u0026#34;fmt\u0026#34;  \u0026#34;net/http\u0026#34; )  func main(){  resp, err := http.Get(\u0026#34;http://example.com/\u0026#34;)  if err != nil {  fmt.Println(err)  return  }  fmt.Println(resp) } 自定义错误  当我们编写自己的函数时，有些情况下我们会遇到错误。可以在错误对象的帮助下返回这些错误：\nfunc Increment(n int) (int, error) {  if n \u0026lt; 0 {  // return error object  return nil, errors.New(\u0026#34;math: cannot process negative number\u0026#34;)  }  return (n + 1), nil } func main() {  num := 5   if inc, err := Increment(num); err != nil {  fmt.Printf(\u0026#34;Failed Number: %v, error message: %v\u0026#34;, num, err)  }else {  fmt.Printf(\u0026#34;Incremented Number: %v\u0026#34;, inc)  } }  在Go中构建的大多数包或我们使用的外部包都有错误处理机制。所以我们调用的任何函数都可能存在错误。这些错误永远不应该被忽略，并且总是在我们称之为函数的地方优雅地处理，就像我们在上面的例子中所做的那样。\nPanic panic是一种未经处理的事件，在程序执行期间突然遇到。在Go中，panic不是处理程序中异常的理想方式。建议使用错误对象。发生panic时程序会停止执行。panic之后执行的事件就是defer。\nDefer  defer总是在函数结束时执行。\npackage main  import \u0026#34;fmt\u0026#34;  func main() {  f()  fmt.Println(\u0026#34;Returned normally from f.\u0026#34;) }  func f() {  defer func() {  if r := recover(); r != nil {  fmt.Println(\u0026#34;Recovered in f\u0026#34;, r)  }  }()  fmt.Println(\u0026#34;Calling g.\u0026#34;)  g(0)  fmt.Println(\u0026#34;Returned normally from g.\u0026#34;) }  func g(i int) {  if i \u0026gt; 3 {  fmt.Println(\u0026#34;Panicking!\u0026#34;)  panic(fmt.Sprintf(\u0026#34;%v\u0026#34;, i))  }  defer fmt.Println(\u0026#34;Defer in g\u0026#34;, i)  fmt.Println(\u0026#34;Printing in g\u0026#34;, i)  g(i + 1) }  在上面的例子中，我们使用panic()来故意终止程序的执行。正如你所注意到的，有一个defer语句，它将使程序在程序执行结束时执行该行。当我们需要在函数结束时执行某些操作时，也可以使用defer，例如关闭文件。\n并发  Go是建立在并发性的基础上的。Go中的并发可以通过轻量级线程的Go例程来实现。\n协程(go routine)  go协程routine是可以与另一个函数并行或同时运行的函数。创建go协程非常简单。只需在函数前面添加关键字go，我们就可以使它并行执行。go协程非常轻量级，因此我们可以创建数千个协程。让我们看一个简单的例子：\npackage main import (  \u0026#34;fmt\u0026#34;  \u0026#34;time\u0026#34; ) func main() {  go c()  fmt.Println(\u0026#34;I am main\u0026#34;)  time.Sleep(time.Second * 2) } func c() {  time.Sleep(time.Second * 2)  fmt.Println(\u0026#34;I am concurrent\u0026#34;) } // I am main // I am concurrent  正如上面的示例，函数c()是一个Go协程，它与主Go线程并行执行。有时我们希望在多个线程之间共享资源。Go更倾向于一个线程的变量不与另一个线程共享，因为这会增加死锁和资源等待的可能性。还有另一种在Go协程之间共享资源的方法：管道Channels。\n管道（channel）  我们可以使用通道在两个Go协程之间传递数据。在创建channel时，必须指定channel接收的数据类型。让我们创建一个字符串类型的简单channel，如下所示：\nc := make(chan string)  使用此channel，我们可以发送字符串类型数据。可以在此频道中发送和接收数据：\npackage main  import \u0026#34;fmt\u0026#34;  func main(){  c := make(chan string)  go func(){ c \u0026lt;- \u0026#34;hello\u0026#34; }()  msg := \u0026lt;-c  fmt.Println(msg) } //\u0026#34;hello\u0026#34;  接收方等待发送方向channel发送数据。\n单向通道  在某些情况下，我们希望Go协程通过channel接收数据但不发送数据，反之亦然。为此，我们还可以创建单向通道。让我们看一个简单的例子：\npackage main  import (  \u0026#34;fmt\u0026#34; )  func main() {  ch := make(chan string)   go sc(ch)  fmt.Println(\u0026lt;-ch) }  func sc(ch chan\u0026lt;- string) {  ch \u0026lt;- \u0026#34;hello\u0026#34; }  在上面的例子中，sc是一个Go协程，它只能向通道发送消息但不能接收消息。\n使用select为Go例程组织多个通道  函数可能有多个通道正在等待执行。为此，我们可以使用select语句。让我们看一个更清晰的例子：：\npackage main  import (  \u0026#34;fmt\u0026#34;  \u0026#34;time\u0026#34; )  func main() {  c1 := make(chan string)  c2 := make(chan string)  go speed1(c1)  go speed2(c2)  fmt.Println(\u0026#34;The first to arrive is:\u0026#34;)  select {  case s1 := \u0026lt;-c1:  fmt.Println(s1)  case s2 := \u0026lt;-c2:  fmt.Println(s2)  } }  func speed1(ch chan string) {  time.Sleep(2 * time.Second)  ch \u0026lt;- \u0026#34;speed 1\u0026#34; }  func speed2(ch chan string) {  time.Sleep(1 * time.Second)  ch \u0026lt;- \u0026#34;speed 2\u0026#34; }  在上面的示例中，main正在等待两个管道c1和c2。使用select case语句打印主函数，消息从管道发送，无论它先收到哪个。\n缓冲通道  有些情况下我们需要向管道发送多个数据。可以为此创建缓冲通道buffered channel。使用缓冲通道，接收器在缓冲区已满之前不会收到消息。我们来看看这个例子：\npackage main  import \u0026#34;fmt\u0026#34;  func main(){  ch := make(chan string, 2)  ch \u0026lt;- \u0026#34;hello\u0026#34;  ch \u0026lt;- \u0026#34;world\u0026#34;  fmt.Println(\u0026lt;-ch) } 结尾 为什么Golang会成功?\n 简单… — Rob-pike\n 目前为止我们已经了解了Go的一些主要组件和功能：\n 变量，数据类型 Array、Slices和Map 函数 循环和条件语句 指针 包 结构、方法和接口 错误处理 并发 - Go routine和channel  恭喜你，你现在对Go有了不错的认识。\n   抛弃了1000行代码的那天是我最富有成效的日子之一。\n                  — Ken Thompson\n 不要止步于此，继续前进。在大脑中思考一个小规模的应用程序并开始构建。\n","permalink":"https://lvlv.fun/posts/2018-12-28/","summary":"作者：Milap Neupane\n链接：https://medium.freecodecamp.org/learning-go-from-zero-to-hero-d2a3223b3d86\n 函数  main.go包中定义的func main()是执行程序的入口。可以定义和使用更多函数。让我们看一个简单的例子：\nfunc add(a int, b int) int {  c := a + b  return c } func main() {  fmt.Println(add(2, 1)) } // 3  正如我们在上面的例子中所看到的，使用**func关键字后跟函数名来定义Go函数。函数所需的参数**需要根据其数据类型定义，最后是返回的数据类型。\n 函数的返回也可以在函数中预定义：\nfunc add(a int, b int) (c int) {  c = a + b  return } func main() {  fmt.Println(add(2, 1)) } // 3  这里c被定义为返回变量。因此，定义的变量c将自动返回，而无需在结尾的return语句中定义。\n 还可以从单个函数返回多个返回值，将返回值与逗号分隔开。\nfunc add(a int, b int) (int, string) {  c := a + b  return c, \u0026#34;successfully added\u0026#34; } func main() {  sum, message := add(2, 1)  fmt.","title":"Learning go from zero to hero - Part 2"},{"content":" 作者：Milap Neupane\n链接：https://medium.freecodecamp.org/learning-go-from-zero-to-hero-d2a3223b3d86\n 开始  想到刚开始学习Go的时候，也是不清不楚地本着拿来能用就行的心态，没有系统学习，导致学习过程中踩坑无数。今天发现一篇文章写的很好，Go语言的特征讲得很细，翻译给需要的初学Go的同学。\n前言  让我们从Go（或者称为Golang）的一个小介绍开始。Go由Google工程师Robert Griesemer，Rob Pike和Ken Thompson设计。它是一种静态类型的编译语言。第一个版本于2012年3月作为开源发布。\n  “ Go是一种开源编程语言，可以轻松构建简单，可靠，高效的软件 ”\n  在许多语言中，有许多方法可以解决给定的问题。程序员可以花很多时间思考解决问题的最佳方法。\n 另一方面，Go相信更少的功能 — 只有一种正确的方法来解决问题。\n 这节省了开发人员的时间，并使大型代码库易于维护。\n  “ 功能越多，成本越高 ” — Rob Pike\n 入门  Go由package组成。名为main的包告诉Go编译器被编译为可执行文件，而不是作为library被引用。它是应用程序的主入口。主包定义为：\npackage main  让我们在Go工作区中创建一个简单的hello world示例。\n工作区  Go中的工作空间由环境变量定义，称为 GOPATH。\n 你的任何代码都将写在工作区内。Go将搜索GOPATH目录中的任何包，或者GOROOT在安装Go时默认设置的目录。注：GOROOT 是安装go的路径。\n 设置GOPATH为所需的目录。现在，让我们将其添加到文件夹中~/workspace。\n# 定义GOPATH目录 export GOPATH=~/workspace # 进入工作区目录 cd ~/workspace  在我们刚刚创建的工作区文件夹中创建main.go文件并写入以下代码。\nHello World! package main  import (  \u0026#34;fmt\u0026#34; )  func main(){  fmt.Println(\u0026#34;Hello World!\u0026#34;) }  在上面的示例中，Go中的官方包fmt实现了格式化I/O的函数。\n 我们使用import 关键字在Go中导入fmt包。func main是代码执行的主入口。Println是fmt包内的一个函数，我们用它来打印“hello world”。\n 让我们先运行这个文件看看。可以通过两种方式运行Go命令。众所周知，Go是编译型语言，所以我们要在执行之前编译它。\ngo build main.go  这将创建一个二进制可执行文件main，现在我们可以运行：\n./main # Hello World！  还有另一种更简单的方式来运行程序。使用go run命令有助于抽象编译步骤。只需运行以下命令即可编译并执行该程序。\ngo run main.go # Hello World!  注意： 你可以在 https://play.golang.org/ 练习以上代码\n变量  Go中的变量是明确声明的。Go是一种静态类型语言。这意味着在变量声明时检查变量类型。\n 声明变量方法如下：\nvar a int  在这种情况下，a将自动设默认值为0。\n 使用以下语法声明变量并赋值：\nvar a = 1  这里变量自动指定为int类型。我们可以使用变量声明的简写方式：\nmessage := \u0026#34;hello world\u0026#34;  还可以在同一行中声明多个变量：\nvar b, c int = 2, 3 数据类型  与任何其他编程语言一样，Go支持各种不同的数据结构。让我们继续学习：\n数字，字符串和布尔值  Go支持的整数类型包括\nint, int8, int16, int32, int64,uint, uint8, uint16, uint32, uint64, uintptr ...  字符串类型存储一系列字节。它用关键字string声明\n 布尔值使用关键字bool声明\n Go还支持复数类型数据类型，可以使用complex64和complex128声明。\nvar a bool = true var b int = 1 var c string = \u0026#39;hello world\u0026#39; var d float32 = 1.222 var x complex128 = cmplx.Sqrt(-5 + 12i) Array, Slice, 和 Map  数组array是相同数据类型的元素序列。数组具有在声明中定义的固定长度，因此不能进行扩展。数组声明为：\nvar a [5]int  数组也可以是多维的。我们可以使用以下格式创建多维数组：\nvar multiD [2][3]int  数组的值在运行时无法更改，也不提供获取子数组的能力。为此，Go有一个名为切片slices的数据类型。\n 切片slices存储一系列元素，可以随时扩展。切片声明类似于数组声明\n 未定义容量的slice：\nvar b []int  这将创建一个零容量和零长度的切片。\n 切片也可以定义容量和长度。我们可以使用以下语法：\nnumbers := make([]int,5,10)  上面定义的切片的初始长度为5，容量为10。\n 切片是数组的抽象。切片使用数组作为底层结构。切片包含三个组件：容量，长度和指向底层数组的指针，如下图所示：\n 图片源： https://blog.golang.org/go-slices-usage-and-internals\n 通过使用append()或copy()函数可以增加切片的容量。append函数可以为数组的末尾增加值，并在需要时增加容量：\nnumbers = append(numbers, 1, 2, 3, 4)  增加切片容量的另一种方法是使用copy()函数。只需创建另一个具有更大容量的切片，并将原始切片复制到新创建的切片：\n// 创建新的切片 number2 := make([]int, 15) // 将原始切片复制到新创建的切片 copy(number2, number)  我们可以创建切片的子切片。这可以使用以下命令完成：\n// 声明一个内含{1,2,3,4}共4个元素的切片 number2 = []int{1,2,3,4} fmt.Println(numbers) // -\u0026gt; [1 2 3 4] // 创建子切片 slice1 := number2[2:] fmt.Println(slice1) // -\u0026gt; [3 4] slice2 := number2[:3] fmt.Println(slice2) // -\u0026gt; [1 2 3] slice3 := number2[1:4] fmt.Println(slice3) // -\u0026gt; [2 3 4]  映射表map是Go中的数据类型，它将键映射到值。我们可以使用以下代码定义键值对映射：\nvar m map[string]int  我们声明了一个名为m的map类型的变量，其键是string类型，值是int类型。我们可以轻松地将键和值添加到map中：\n// 添加 key/value m[\u0026#39;clearity\u0026#39;] = 2 m[\u0026#39;simplicity\u0026#39;] = 3 // 打印输出 value fmt.Println(m[\u0026#39;clearity\u0026#39;]) // -\u0026gt; 2 fmt.Println(m[\u0026#39;simplicity\u0026#39;]) // -\u0026gt; 3 类型转换  可以使用类型转换将一种类型的数据类型转换为另一种类型。我们来看一个简单的类型转换：\na := 1.1 b := int(a) fmt.Println(b) //-\u0026gt; 1  并非所有类型的数据类型都可以转换为其他类型。确保数据类型与转换类型兼容。\n​\n流程控制 if else  我们可以使用if-else语句，如下例所示。确保花括号与条件位于同一行。\nif num := 9; num \u0026lt; 0 { \tfmt.Println(num, \u0026#34;小于0\u0026#34;) } else if num \u0026lt; 10 { \tfmt.Println(num, \u0026#34;是一位数\u0026#34;) } else { \tfmt.Println(num, \u0026#34;是多位数\u0026#34;) } switch case  switch-case有助于组织多个条件语句。以下实例表示一个简单的switch case语句：\ni := 2 switch i { \tcase 1: \tfmt.Println(\u0026#34;one\u0026#34;) \tcase 2: \tfmt.Println(\u0026#34;two\u0026#34;) \tdefault: \tfmt.Println(\u0026#34;none\u0026#34;) } 循环  Go使用for来实现不同类型的循环：\ni := 0 sum := 0 for i \u0026lt; 10 { \tsum += 1 \ti++ } fmt.Println(sum)  上面的示例类似于C中的while循环。对于for循环，还可以使用相同的for语句：\nsum := 0 for i := 0; i \u0026lt; 10; i++ { \tsum += i } fmt.Println(sum)  Go中的无限循环：\nfor { } 指针  Go提供指针。指针是保存值的内存地址的地方。指针由*定义。\n 根据数据类型定义指针，例如：\nvar ap *int  变量ap是指向整数类型的指针。使用\u0026amp;操作可用于获取变量的地址。\na := 12 ap = \u0026amp;a  可以使用*运算符访问指针指向的值：\nfmt.Println(*ap) // 12  在将结构作为参数传递或者为已定义类型声明方法时，通常首选指针。\n 传递值时，实际复制的值意味着更多的内存 传递指针后，函数更改的值将反映在方法/函数调用者中   例如：\nfunc increment(i *int) { \t*i++ } func main() {  i := 10  increment(\u0026amp;i)  fmt.Println(i) } // 11  注意： 在博客中尝试示例代码时，不要忘记将其包含在main包中，并在需要时导入fmt或其他包，如上面第一个main.go示例所示。\n","permalink":"https://lvlv.fun/posts/2018-12-22/","summary":"作者：Milap Neupane\n链接：https://medium.freecodecamp.org/learning-go-from-zero-to-hero-d2a3223b3d86\n 开始  想到刚开始学习Go的时候，也是不清不楚地本着拿来能用就行的心态，没有系统学习，导致学习过程中踩坑无数。今天发现一篇文章写的很好，Go语言的特征讲得很细，翻译给需要的初学Go的同学。\n前言  让我们从Go（或者称为Golang）的一个小介绍开始。Go由Google工程师Robert Griesemer，Rob Pike和Ken Thompson设计。它是一种静态类型的编译语言。第一个版本于2012年3月作为开源发布。\n  “ Go是一种开源编程语言，可以轻松构建简单，可靠，高效的软件 ”\n  在许多语言中，有许多方法可以解决给定的问题。程序员可以花很多时间思考解决问题的最佳方法。\n 另一方面，Go相信更少的功能 — 只有一种正确的方法来解决问题。\n 这节省了开发人员的时间，并使大型代码库易于维护。\n  “ 功能越多，成本越高 ” — Rob Pike\n 入门  Go由package组成。名为main的包告诉Go编译器被编译为可执行文件，而不是作为library被引用。它是应用程序的主入口。主包定义为：\npackage main  让我们在Go工作区中创建一个简单的hello world示例。\n工作区  Go中的工作空间由环境变量定义，称为 GOPATH。\n 你的任何代码都将写在工作区内。Go将搜索GOPATH目录中的任何包，或者GOROOT在安装Go时默认设置的目录。注：GOROOT 是安装go的路径。\n 设置GOPATH为所需的目录。现在，让我们将其添加到文件夹中~/workspace。\n# 定义GOPATH目录 export GOPATH=~/workspace # 进入工作区目录 cd ~/workspace  在我们刚刚创建的工作区文件夹中创建main.go文件并写入以下代码。\nHello World! package main  import (  \u0026#34;fmt\u0026#34; )  func main(){  fmt.","title":"Learning go from zero to hero - Part 1"},{"content":"","permalink":"https://lvlv.fun/live/","summary":"live","title":"Live"},{"content":"","permalink":"https://lvlv.fun/navigation/","summary":"navigation","title":"Navigation"}]