<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Problem on Lv&#39;s Playground</title>
    <link>https://lvlv.fun/tags/problem/</link>
    <description>Recent content in Problem on Lv&#39;s Playground</description>
    <generator>Hugo -- 0.129.0</generator>
    <language>en</language>
    <lastBuildDate>Mon, 22 Jul 2019 12:40:20 +0800</lastBuildDate>
    <atom:link href="https://lvlv.fun/tags/problem/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>gRPC Connection reset by peer 问题</title>
      <link>https://lvlv.fun/posts/2019-07-22/</link>
      <pubDate>Mon, 22 Jul 2019 12:40:20 +0800</pubDate>
      <guid>https://lvlv.fun/posts/2019-07-22/</guid>
      <description>前提 因产品需求，需用 PHP（v7.0.12）调用 k8s 集群中 gRPC（golang@1.12.0）服务。
问题 经过 dev 环境测试，当 php-fpm 启动后第一次调用或者距离上次调用时间 20 分钟后左右，再次请求 gRPC 微服务接口，就会返回 Connection reset by peer 错误，说明 gRPC 服务端或者客户端主动关闭连接了。继续发起请求到服务端，又恢复正常。
思考 经查阅相关资料，发现问题可能出现在 k8s 集群的 kube-proxy 模式上。当前 k8s 环境 (dev) 下的 kube-proxy 为 ipvs 模式，服务端与客户端之间通信如下：
把上图 client 看成是 apsopen-inside 服务 pod，Backend pod(1~3) 看成 gRPC 服务，可以看出它们之间的交互路径：
---&amp;gt; gRPC server pod1 gRPC-client ---&amp;gt; ipvs ---&amp;gt; gRPC server pod3 ---&amp;gt; gRPC server pod3 我们知道gRPC是基于HTTP/2协议的，gRPC的client和server在交互时会建立多条连接，为了性能，这些连接都是长连接并且是一直保活的。这段环境中不管是客户端服务还是 gRPC 服务都被调度到各个相同配置信息的 Kubernetes 节点上，这些 k8s 节点的 keep-alive 是一致的，如果出现连接主动关闭的问题，因为从 client 到 server 经历了一层 ipvs，所以最大的可能就是 ipvs 出将连接主动断开，而 client 端还不知情。 搜索 ipvs timeout 关键字找到了下面相关的链接：</description>
    </item>
  </channel>
</rss>
